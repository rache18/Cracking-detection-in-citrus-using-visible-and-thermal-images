{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"T4","authorship_tag":"ABX9TyNMYbGT2zK2vi+l3s8FwpyX"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# This code is cased on what represented in the paper: A Convolutional Neural Network approach for image-based anomaly detection in smart agriculture Paper"],"metadata":{"id":"KsLXVLwY6GV3"}},{"cell_type":"markdown","source":["mount"],"metadata":{"id":"mP6KubSTc31Y"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PLBNv60ecy2W","executionInfo":{"status":"ok","timestamp":1741855538036,"user_tz":-120,"elapsed":24200,"user":{"displayName":"Racheli Eliyahu","userId":"04395325802416145775"}},"outputId":"a62fef42-d619-4ebb-eea4-290333892df4"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]}],"source":["# Import images from google drive\n","\n","#connect to google drive - mount\n","from google.colab import drive\n","drive.mount('/content/gdrive', force_remount=True)"]},{"cell_type":"markdown","source":["cloning to article"],"metadata":{"id":"l5Law1ShdEj1"}},{"cell_type":"code","source":["!git clone https://github.com/josemenber/image-based-crop-anomaly-detection.git\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MEsJxj_rc8_8","executionInfo":{"status":"ok","timestamp":1741247822732,"user_tz":-120,"elapsed":48026,"user":{"displayName":"Racheli Eliyahu","userId":"04395325802416145775"}},"outputId":"6dcbd218-fd80-4715-bd0e-3bf57c58a68d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'image-based-crop-anomaly-detection'...\n","remote: Enumerating objects: 17582, done.\u001b[K\n","remote: Total 17582 (delta 0), reused 0 (delta 0), pack-reused 17582 (from 1)\u001b[K\n","Receiving objects: 100% (17582/17582), 890.65 MiB | 23.39 MiB/s, done.\n","Resolving deltas: 100% (42/42), done.\n","Updating files: 100% (17518/17518), done.\n"]}]},{"cell_type":"markdown","source":["cahnge images and label.csv to my data 2023 ( anomalies )"],"metadata":{"id":"sUmWTHWWdNSy"}},{"cell_type":"code","source":["# # Delete existing images in the images directory\n","!rm -rf /content/image-based-crop-anomaly-detection/images/*\n","\n","# Delete the existing labels.csv file\n","!rm /content/image-based-crop-anomaly-detection/labels/labels.csv\n"],"metadata":{"id":"Vrg2TictdIlJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Path to your images directory and CSV file in Google Drive\n","images_path_in_drive = '/content/gdrive/Othercomputers/My PC/Thesis/Segmented_by_SAM/2023/All_RGB/anomaly_original_size_4'\n","labels_csv_in_drive = '/content/gdrive/Othercomputers/My PC/Thesis/Segmented_by_SAM/2023/All_RGB/anomaly_detected_scope_4/tabular/labels.csv'\n"],"metadata":{"id":"KPXjdIWpdP6p"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Copy images from Drive to the Colab environment\n","!cp -r \"$images_path_in_drive\"/* /content/image-based-crop-anomaly-detection/images/\n","\n","# Copy the CSV file from Drive to the Colab environment\n","!cp \"$labels_csv_in_drive\" /content/image-based-crop-anomaly-detection/labels/labels.csv\n"],"metadata":{"id":"dY2qwArPdRZb"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["run train"],"metadata":{"id":"Ap44NXPldTEL"}},{"cell_type":"code","source":["# %cd /content/image-based-crop-anomaly-detection\n","\n","\n","%cd /content/gdrive/Othercomputers/My PC/Thesis/Anomaly_article_original\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"32vzpnEidXk8","executionInfo":{"status":"ok","timestamp":1741465667319,"user_tz":-120,"elapsed":42,"user":{"displayName":"Racheli Eliyahu","userId":"04395325802416145775"}},"outputId":"118f41ba-4c65-4dde-9abd-4335a2f77649"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/gdrive/Othercomputers/My PC/Thesis/Anomaly_article_original\n"]}]},{"cell_type":"code","source":["!pip install -r requirements.txt\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QRr5-9exda7O","executionInfo":{"status":"ok","timestamp":1741465673672,"user_tz":-120,"elapsed":2392,"user":{"displayName":"Racheli Eliyahu","userId":"04395325802416145775"}},"outputId":"2d4297dd-3dd5-4ef5-c239-2338f3a0c0d7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[31mERROR: Could not find a version that satisfies the requirement python>=3.6.6 (from versions: none)\u001b[0m\u001b[31m\n","\u001b[0m\u001b[31mERROR: No matching distribution found for python>=3.6.6\u001b[0m\u001b[31m\n","\u001b[0m"]}]},{"cell_type":"markdown","source":["delete if exists : augmented images"],"metadata":{"id":"c8vIr7N3d9-q"}},{"cell_type":"code","source":["import os\n","import shutil\n","\n","# Specify the directory path\n","directory_path = '/content/image-based-crop-anomaly-detection/new_images'\n","\n","# Check if the directory exists\n","if os.path.exists(directory_path):\n","    # Remove the directory and all its contents\n","    shutil.rmtree(directory_path)\n","    print(f\"Directory '{directory_path}' has been deleted.\")\n","else:\n","    print(f\"Directory '{directory_path}' does not exist.\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0HGt2NxxeDQj","executionInfo":{"status":"ok","timestamp":1741465652406,"user_tz":-120,"elapsed":31,"user":{"displayName":"Racheli Eliyahu","userId":"04395325802416145775"}},"outputId":"9271a592-ee59-4e25-f9a0-10d600520a4b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Directory '/content/image-based-crop-anomaly-detection/new_images' does not exist.\n"]}]},{"cell_type":"markdown","source":["generate augmentations"],"metadata":{"id":"sxc4WfQbeo2b"}},{"cell_type":"code","source":["!python generate_images.py --noise --num_imgs 3"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mWqgyEE0cc1V","executionInfo":{"status":"ok","timestamp":1741468319315,"user_tz":-120,"elapsed":2615618,"user":{"displayName":"Racheli Eliyahu","userId":"04395325802416145775"}},"outputId":"ddbd777f-d36d-4dd8-ba17-56a7a9b56a27"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["2025-03-08 20:28:26.244252: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n","E0000 00:00:1741465706.265043   15096 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","E0000 00:00:1741465706.271423   15096 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2025-03-08 20:28:26.292486: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"]}]},{"cell_type":"code","source":["!python generate_images.py --noise --num_imgs 3"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"t0sh7qfyeF_7","executionInfo":{"status":"ok","timestamp":1741250650658,"user_tz":-120,"elapsed":2015399,"user":{"displayName":"Racheli Eliyahu","userId":"04395325802416145775"}},"outputId":"59739796-f528-45ce-ab2c-9ed06a72dd58"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["2025-03-06 08:10:37.690704: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n","E0000 00:00:1741248637.742402    7175 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","E0000 00:00:1741248637.758428    7175 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2025-03-06 08:10:37.812041: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"]}]},{"cell_type":"code","source":["import os\n","\n","# Set the directory path\n","directory_path = '/content/image-based-crop-anomaly-detection/images'\n","\n","# Check if the directory exists\n","if os.path.exists(directory_path):\n","    # List all files in the directory\n","    files = os.listdir(directory_path)\n","    # Filter files to count only images\n","    image_files = [file for file in files if file.lower().endswith(('.png', '.jpg', '.jpeg', '.gif', '.bmp', '.tiff'))]\n","    print(f\"There are {len(image_files)} image files in the directory '{directory_path}'.\")\n","else:\n","    print(f\"Directory '{directory_path}' does not exist.\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PcgkC4MVhzUL","executionInfo":{"status":"ok","timestamp":1741250650937,"user_tz":-120,"elapsed":126,"user":{"displayName":"Racheli Eliyahu","userId":"04395325802416145775"}},"outputId":"ae243796-2204-4cfe-8ee1-5244de8484e7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["There are 2866 image files in the directory '/content/image-based-crop-anomaly-detection/images'.\n"]}]},{"cell_type":"markdown","source":["save new version in drive"],"metadata":{"id":"Rl5U0UqU8ogM"}},{"cell_type":"code","source":["!cp -r /content/image-based-crop-anomaly-detection \"/content/gdrive/Othercomputers/My PC/Thesis/Anomaly_article_original/\"\n"],"metadata":{"id":"VEIKgC8njY4T","executionInfo":{"status":"ok","timestamp":1741762002253,"user_tz":-120,"elapsed":1121,"user":{"displayName":"Racheli Eliyahu","userId":"04395325802416145775"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"6b13b673-439e-4979-9950-86cb974c404f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["cp: cannot stat '/content/image-based-crop-anomaly-detection': No such file or directory\n"]}]},{"cell_type":"markdown","source":["# TRAIN"],"metadata":{"id":"gKZpN9Bu8q26"}},{"cell_type":"code","source":["!python train_models.py  --model vgg16 --augmentation --max_epochs 50"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9EjbukhKjlQA","executionInfo":{"status":"ok","timestamp":1741269177203,"user_tz":-120,"elapsed":6281336,"user":{"displayName":"Racheli Eliyahu","userId":"04395325802416145775"}},"outputId":"0d317ef8-2297-492f-869f-fdc101af51d3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["2025-03-06 12:08:17.179859: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n","E0000 00:00:1741262897.198963   34242 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","E0000 00:00:1741262897.204678   34242 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2025-03-06 12:08:17.225495: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","Found 5998 validated image filenames belonging to 4 classes.\n","Found 573 validated image filenames belonging to 4 classes.\n","Found 574 validated image filenames belonging to 4 classes.\n","2025-03-06 12:08:21.815389: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n","I0000 00:00:1741262901.815613   34242 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13942 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n","Epoch 1/50\n","WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n","I0000 00:00:1741262907.208696   34307 service.cc:148] XLA service 0x12d93c016d50 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n","I0000 00:00:1741262907.208731   34307 service.cc:156]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n","2025-03-06 12:08:27.287372: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n","I0000 00:00:1741262907.717744   34307 cuda_dnn.cc:529] Loaded cuDNN version 90300\n","2025-03-06 12:08:28.269277: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:557] Omitted potentially buggy algorithm eng14{k25=0} for conv (f32[32,64,224,224]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,3,224,224]{3,2,1,0}, f32[64,3,3,3]{3,2,1,0}, f32[64]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"leakyrelu_alpha\":0,\"side_input_scale\":0},\"force_earliest_schedule\":false,\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[]}\n","2025-03-06 12:08:28.445973: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:557] Omitted potentially buggy algorithm eng14{k25=0} for conv (f32[32,64,224,224]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,64,224,224]{3,2,1,0}, f32[64,64,3,3]{3,2,1,0}, f32[64]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"leakyrelu_alpha\":0,\"side_input_scale\":0},\"force_earliest_schedule\":false,\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[]}\n","2025-03-06 12:08:30.486361: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:557] Omitted potentially buggy algorithm eng14{k25=0} for conv (f32[32,128,112,112]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,64,112,112]{3,2,1,0}, f32[128,64,3,3]{3,2,1,0}, f32[128]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"leakyrelu_alpha\":0,\"side_input_scale\":0},\"force_earliest_schedule\":false,\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[]}\n","2025-03-06 12:08:31.454784: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:557] Omitted potentially buggy algorithm eng14{k25=0} for conv (f32[32,128,112,112]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,128,112,112]{3,2,1,0}, f32[128,128,3,3]{3,2,1,0}, f32[128]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"leakyrelu_alpha\":0,\"side_input_scale\":0},\"force_earliest_schedule\":false,\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[]}\n","2025-03-06 12:08:33.261136: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:557] Omitted potentially buggy algorithm eng14{k25=0} for conv (f32[32,256,56,56]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,128,56,56]{3,2,1,0}, f32[256,128,3,3]{3,2,1,0}, f32[256]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"leakyrelu_alpha\":0,\"side_input_scale\":0},\"force_earliest_schedule\":false,\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[]}\n","2025-03-06 12:08:34.273695: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:557] Omitted potentially buggy algorithm eng14{k25=0} for conv (f32[32,256,56,56]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,256,56,56]{3,2,1,0}, f32[256,256,3,3]{3,2,1,0}, f32[256]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"leakyrelu_alpha\":0,\"side_input_scale\":0},\"force_earliest_schedule\":false,\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[]}\n","2025-03-06 12:08:36.958240: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:557] Omitted potentially buggy algorithm eng14{k25=0} for conv (f32[32,512,14,14]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,512,14,14]{3,2,1,0}, f32[512,512,3,3]{3,2,1,0}, f32[512]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"leakyrelu_alpha\":0,\"side_input_scale\":0},\"force_earliest_schedule\":false,\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[]}\n","I0000 00:00:1741262938.194062   34307 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n","\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 663ms/step - accuracy: 0.8119 - loss: 0.5330/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n","  self._warn_if_super_not_called()\n","2025-03-06 12:11:03.290744: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:557] Omitted potentially buggy algorithm eng14{k25=0} for conv (f32[32,64,224,224]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,3,224,224]{3,2,1,0}, f32[64,3,3,3]{3,2,1,0}, f32[64]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"cudnn_conv_backend_config\":{\"activation_mode\":\"kRelu\",\"conv_result_scale\":1,\"leakyrelu_alpha\":0,\"side_input_scale\":0},\"force_earliest_schedule\":false,\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[]}\n","2025-03-06 12:11:03.416866: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:557] Omitted potentially buggy algorithm eng14{k25=0} for conv (f32[32,64,224,224]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,64,224,224]{3,2,1,0}, f32[64,64,3,3]{3,2,1,0}, f32[64]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"cudnn_conv_backend_config\":{\"activation_mode\":\"kRelu\",\"conv_result_scale\":1,\"leakyrelu_alpha\":0,\"side_input_scale\":0},\"force_earliest_schedule\":false,\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[]}\n","2025-03-06 12:11:05.947634: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:557] Omitted potentially buggy algorithm eng14{k25=0} for conv (f32[32,128,112,112]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,64,112,112]{3,2,1,0}, f32[128,64,3,3]{3,2,1,0}, f32[128]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"cudnn_conv_backend_config\":{\"activation_mode\":\"kRelu\",\"conv_result_scale\":1,\"leakyrelu_alpha\":0,\"side_input_scale\":0},\"force_earliest_schedule\":false,\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[]}\n","2025-03-06 12:11:07.219385: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:557] Omitted potentially buggy algorithm eng14{k25=0} for conv (f32[32,128,112,112]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,128,112,112]{3,2,1,0}, f32[128,128,3,3]{3,2,1,0}, f32[128]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"cudnn_conv_backend_config\":{\"activation_mode\":\"kRelu\",\"conv_result_scale\":1,\"leakyrelu_alpha\":0,\"side_input_scale\":0},\"force_earliest_schedule\":false,\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[]}\n","2025-03-06 12:11:08.950147: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:557] Omitted potentially buggy algorithm eng14{k25=0} for conv (f32[32,256,56,56]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,128,56,56]{3,2,1,0}, f32[256,128,3,3]{3,2,1,0}, f32[256]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"cudnn_conv_backend_config\":{\"activation_mode\":\"kRelu\",\"conv_result_scale\":1,\"leakyrelu_alpha\":0,\"side_input_scale\":0},\"force_earliest_schedule\":false,\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[]}\n","2025-03-06 12:11:09.839018: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:557] Omitted potentially buggy algorithm eng14{k25=0} for conv (f32[32,256,56,56]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,256,56,56]{3,2,1,0}, f32[256,256,3,3]{3,2,1,0}, f32[256]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"cudnn_conv_backend_config\":{\"activation_mode\":\"kRelu\",\"conv_result_scale\":1,\"leakyrelu_alpha\":0,\"side_input_scale\":0},\"force_earliest_schedule\":false,\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[]}\n","2025-03-06 12:11:13.101537: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:557] Omitted potentially buggy algorithm eng14{k25=0} for conv (f32[32,512,14,14]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,512,14,14]{3,2,1,0}, f32[512,512,3,3]{3,2,1,0}, f32[512]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"cudnn_conv_backend_config\":{\"activation_mode\":\"kRelu\",\"conv_result_scale\":1,\"leakyrelu_alpha\":0,\"side_input_scale\":0},\"force_earliest_schedule\":false,\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[]}\n","\n","Epoch 1: val_loss improved from inf to 0.56698, saving model to ./model_checkpoints/best_model.h5\n","WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n","\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m176s\u001b[0m 758ms/step - accuracy: 0.8119 - loss: 0.5326 - val_accuracy: 0.7978 - val_loss: 0.5670 - learning_rate: 1.0000e-04\n","Epoch 2/50\n","2025-03-06 12:11:20.546650: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:557] Omitted potentially buggy algorithm eng14{k25=0} for conv (f32[14,64,224,224]{3,2,1,0}, u8[0]{0}) custom-call(f32[14,3,224,224]{3,2,1,0}, f32[64,3,3,3]{3,2,1,0}, f32[64]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"leakyrelu_alpha\":0,\"side_input_scale\":0},\"force_earliest_schedule\":false,\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[]}\n","2025-03-06 12:11:20.624629: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:557] Omitted potentially buggy algorithm eng14{k25=0} for conv (f32[14,64,224,224]{3,2,1,0}, u8[0]{0}) custom-call(f32[14,64,224,224]{3,2,1,0}, f32[64,64,3,3]{3,2,1,0}, f32[64]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"leakyrelu_alpha\":0,\"side_input_scale\":0},\"force_earliest_schedule\":false,\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[]}\n","2025-03-06 12:11:21.781959: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:557] Omitted potentially buggy algorithm eng14{k25=0} for conv (f32[14,128,112,112]{3,2,1,0}, u8[0]{0}) custom-call(f32[14,64,112,112]{3,2,1,0}, f32[128,64,3,3]{3,2,1,0}, f32[128]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"leakyrelu_alpha\":0,\"side_input_scale\":0},\"force_earliest_schedule\":false,\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[]}\n","2025-03-06 12:11:22.369258: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:557] Omitted potentially buggy algorithm eng14{k25=0} for conv (f32[14,128,112,112]{3,2,1,0}, u8[0]{0}) custom-call(f32[14,128,112,112]{3,2,1,0}, f32[128,128,3,3]{3,2,1,0}, f32[128]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"leakyrelu_alpha\":0,\"side_input_scale\":0},\"force_earliest_schedule\":false,\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[]}\n","2025-03-06 12:11:23.449424: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:557] Omitted potentially buggy algorithm eng14{k25=0} for conv (f32[14,256,56,56]{3,2,1,0}, u8[0]{0}) custom-call(f32[14,128,56,56]{3,2,1,0}, f32[256,128,3,3]{3,2,1,0}, f32[256]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"leakyrelu_alpha\":0,\"side_input_scale\":0},\"force_earliest_schedule\":false,\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[]}\n","2025-03-06 12:11:24.000111: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:557] Omitted potentially buggy algorithm eng14{k25=0} for conv (f32[14,256,56,56]{3,2,1,0}, u8[0]{0}) custom-call(f32[14,256,56,56]{3,2,1,0}, f32[256,256,3,3]{3,2,1,0}, f32[256]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"leakyrelu_alpha\":0,\"side_input_scale\":0},\"force_earliest_schedule\":false,\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[]}\n","2025-03-06 12:11:24.805664: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:557] Omitted potentially buggy algorithm eng14{k25=0} for conv (f32[14,512,28,28]{3,2,1,0}, u8[0]{0}) custom-call(f32[14,256,28,28]{3,2,1,0}, f32[512,256,3,3]{3,2,1,0}, f32[512]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"leakyrelu_alpha\":0,\"side_input_scale\":0},\"force_earliest_schedule\":false,\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[]}\n","2025-03-06 12:11:25.296569: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:557] Omitted potentially buggy algorithm eng14{k25=0} for conv (f32[14,512,28,28]{3,2,1,0}, u8[0]{0}) custom-call(f32[14,512,28,28]{3,2,1,0}, f32[512,512,3,3]{3,2,1,0}, f32[512]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"leakyrelu_alpha\":0,\"side_input_scale\":0},\"force_earliest_schedule\":false,\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[]}\n","2025-03-06 12:11:25.865998: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:557] Omitted potentially buggy algorithm eng14{k25=0} for conv (f32[14,512,14,14]{3,2,1,0}, u8[0]{0}) custom-call(f32[14,512,14,14]{3,2,1,0}, f32[512,512,3,3]{3,2,1,0}, f32[512]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"leakyrelu_alpha\":0,\"side_input_scale\":0},\"force_earliest_schedule\":false,\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[]}\n","\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 650ms/step - accuracy: 0.8558 - loss: 0.3653\n","Epoch 2: val_loss improved from 0.56698 to 0.49582, saving model to ./model_checkpoints/best_model.h5\n","WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n","\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m146s\u001b[0m 680ms/step - accuracy: 0.8558 - loss: 0.3653 - val_accuracy: 0.8015 - val_loss: 0.4958 - learning_rate: 1.0000e-04\n","Epoch 3/50\n","\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 648ms/step - accuracy: 0.8657 - loss: 0.3650\n","Epoch 3: val_loss did not improve from 0.49582\n","\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 667ms/step - accuracy: 0.8657 - loss: 0.3649 - val_accuracy: 0.8015 - val_loss: 0.6575 - learning_rate: 1.0000e-04\n","Epoch 4/50\n","\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 665ms/step - accuracy: 0.8798 - loss: 0.3201\n","Epoch 4: val_loss improved from 0.49582 to 0.39097, saving model to ./model_checkpoints/best_model.h5\n","WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n","\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m130s\u001b[0m 696ms/step - accuracy: 0.8799 - loss: 0.3200 - val_accuracy: 0.8585 - val_loss: 0.3910 - learning_rate: 1.0000e-04\n","Epoch 5/50\n","\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 660ms/step - accuracy: 0.8932 - loss: 0.2776\n","Epoch 5: val_loss improved from 0.39097 to 0.37334, saving model to ./model_checkpoints/best_model.h5\n","WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n","\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m129s\u001b[0m 693ms/step - accuracy: 0.8932 - loss: 0.2776 - val_accuracy: 0.8585 - val_loss: 0.3733 - learning_rate: 1.0000e-04\n","Epoch 6/50\n","\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 639ms/step - accuracy: 0.8997 - loss: 0.2689\n","Epoch 6: val_loss improved from 0.37334 to 0.25842, saving model to ./model_checkpoints/best_model.h5\n","WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n","\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 669ms/step - accuracy: 0.8997 - loss: 0.2689 - val_accuracy: 0.8989 - val_loss: 0.2584 - learning_rate: 1.0000e-04\n","Epoch 7/50\n","\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 656ms/step - accuracy: 0.9158 - loss: 0.2384\n","Epoch 7: val_loss did not improve from 0.25842\n","\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 675ms/step - accuracy: 0.9158 - loss: 0.2384 - val_accuracy: 0.8805 - val_loss: 0.3032 - learning_rate: 1.0000e-04\n","Epoch 8/50\n","\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 669ms/step - accuracy: 0.9062 - loss: 0.2534\n","Epoch 8: val_loss did not improve from 0.25842\n","\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m128s\u001b[0m 686ms/step - accuracy: 0.9062 - loss: 0.2534 - val_accuracy: 0.8732 - val_loss: 0.3621 - learning_rate: 1.0000e-04\n","Epoch 9/50\n","\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 673ms/step - accuracy: 0.9262 - loss: 0.2114\n","Epoch 9: val_loss did not improve from 0.25842\n","\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m129s\u001b[0m 692ms/step - accuracy: 0.9262 - loss: 0.2115 - val_accuracy: 0.9136 - val_loss: 0.2775 - learning_rate: 1.0000e-04\n","Epoch 10/50\n","\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 662ms/step - accuracy: 0.9153 - loss: 0.2380\n","Epoch 10: val_loss did not improve from 0.25842\n","\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 679ms/step - accuracy: 0.9153 - loss: 0.2379 - val_accuracy: 0.9044 - val_loss: 0.2956 - learning_rate: 1.0000e-04\n","Epoch 11/50\n","\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 642ms/step - accuracy: 0.9309 - loss: 0.2087\n","Epoch 11: val_loss did not improve from 0.25842\n","\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 661ms/step - accuracy: 0.9309 - loss: 0.2087 - val_accuracy: 0.8805 - val_loss: 0.3490 - learning_rate: 1.0000e-04\n","Epoch 12/50\n","\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 650ms/step - accuracy: 0.9274 - loss: 0.1974\n","Epoch 12: val_loss did not improve from 0.25842\n","\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 668ms/step - accuracy: 0.9274 - loss: 0.1974 - val_accuracy: 0.9099 - val_loss: 0.3035 - learning_rate: 1.0000e-04\n","Epoch 13/50\n","\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 657ms/step - accuracy: 0.9317 - loss: 0.1931\n","Epoch 13: val_loss improved from 0.25842 to 0.19365, saving model to ./model_checkpoints/best_model.h5\n","WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n","\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m128s\u001b[0m 688ms/step - accuracy: 0.9317 - loss: 0.1931 - val_accuracy: 0.9320 - val_loss: 0.1937 - learning_rate: 1.0000e-04\n","Epoch 14/50\n","\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 644ms/step - accuracy: 0.9340 - loss: 0.1877\n","Epoch 14: val_loss did not improve from 0.19365\n","\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 662ms/step - accuracy: 0.9340 - loss: 0.1877 - val_accuracy: 0.9210 - val_loss: 0.2143 - learning_rate: 1.0000e-04\n","Epoch 15/50\n","\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 647ms/step - accuracy: 0.9335 - loss: 0.1749\n","Epoch 15: val_loss did not improve from 0.19365\n","\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 665ms/step - accuracy: 0.9335 - loss: 0.1749 - val_accuracy: 0.8989 - val_loss: 0.2684 - learning_rate: 1.0000e-04\n","Epoch 16/50\n","\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 648ms/step - accuracy: 0.9414 - loss: 0.1734\n","Epoch 16: val_loss improved from 0.19365 to 0.18388, saving model to ./model_checkpoints/best_model.h5\n","WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n","\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 678ms/step - accuracy: 0.9414 - loss: 0.1734 - val_accuracy: 0.9301 - val_loss: 0.1839 - learning_rate: 1.0000e-04\n","Epoch 17/50\n","\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 647ms/step - accuracy: 0.9372 - loss: 0.1786\n","Epoch 17: val_loss did not improve from 0.18388\n","\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 665ms/step - accuracy: 0.9373 - loss: 0.1785 - val_accuracy: 0.9154 - val_loss: 0.2459 - learning_rate: 1.0000e-04\n","Epoch 18/50\n","\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 642ms/step - accuracy: 0.9329 - loss: 0.1773\n","Epoch 18: val_loss improved from 0.18388 to 0.18379, saving model to ./model_checkpoints/best_model.h5\n","WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n","\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 677ms/step - accuracy: 0.9330 - loss: 0.1773 - val_accuracy: 0.9246 - val_loss: 0.1838 - learning_rate: 1.0000e-04\n","Epoch 19/50\n","\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 645ms/step - accuracy: 0.9326 - loss: 0.1918\n","Epoch 19: val_loss did not improve from 0.18379\n","\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 664ms/step - accuracy: 0.9326 - loss: 0.1917 - val_accuracy: 0.9265 - val_loss: 0.2051 - learning_rate: 1.0000e-04\n","Epoch 20/50\n","\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 658ms/step - accuracy: 0.9346 - loss: 0.1752\n","Epoch 20: val_loss did not improve from 0.18379\n","\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 676ms/step - accuracy: 0.9347 - loss: 0.1751 - val_accuracy: 0.9283 - val_loss: 0.1856 - learning_rate: 1.0000e-04\n","Epoch 21/50\n","\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 625ms/step - accuracy: 0.9421 - loss: 0.1753\n","Epoch 21: val_loss did not improve from 0.18379\n","\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m120s\u001b[0m 643ms/step - accuracy: 0.9421 - loss: 0.1753 - val_accuracy: 0.9357 - val_loss: 0.2008 - learning_rate: 1.0000e-04\n","Epoch 22/50\n","\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 630ms/step - accuracy: 0.9419 - loss: 0.1595\n","Epoch 22: val_loss did not improve from 0.18379\n","\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 647ms/step - accuracy: 0.9419 - loss: 0.1595 - val_accuracy: 0.9246 - val_loss: 0.2292 - learning_rate: 1.0000e-04\n","Epoch 23/50\n","\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 647ms/step - accuracy: 0.9420 - loss: 0.1614\n","Epoch 23: val_loss did not improve from 0.18379\n","\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 665ms/step - accuracy: 0.9420 - loss: 0.1614 - val_accuracy: 0.9246 - val_loss: 0.2327 - learning_rate: 1.0000e-04\n","Epoch 24/50\n","\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 666ms/step - accuracy: 0.9407 - loss: 0.1633\n","Epoch 24: val_loss did not improve from 0.18379\n","\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m128s\u001b[0m 684ms/step - accuracy: 0.9407 - loss: 0.1633 - val_accuracy: 0.9265 - val_loss: 0.2590 - learning_rate: 1.0000e-04\n","Epoch 25/50\n","\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 651ms/step - accuracy: 0.9429 - loss: 0.1594\n","Epoch 25: val_loss did not improve from 0.18379\n","\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 670ms/step - accuracy: 0.9430 - loss: 0.1594 - val_accuracy: 0.9301 - val_loss: 0.3113 - learning_rate: 1.0000e-04\n","Epoch 26/50\n","\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 671ms/step - accuracy: 0.9437 - loss: 0.1568\n","Epoch 26: val_loss did not improve from 0.18379\n","\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m129s\u001b[0m 690ms/step - accuracy: 0.9437 - loss: 0.1567 - val_accuracy: 0.9283 - val_loss: 0.2172 - learning_rate: 1.0000e-04\n","Epoch 27/50\n","\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 664ms/step - accuracy: 0.9471 - loss: 0.1523\n","Epoch 27: val_loss did not improve from 0.18379\n","\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 683ms/step - accuracy: 0.9471 - loss: 0.1523 - val_accuracy: 0.9283 - val_loss: 0.1953 - learning_rate: 1.0000e-04\n","Epoch 28/50\n","\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 670ms/step - accuracy: 0.9560 - loss: 0.1381\n","Epoch 28: val_loss did not improve from 0.18379\n","\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m129s\u001b[0m 689ms/step - accuracy: 0.9560 - loss: 0.1381 - val_accuracy: 0.9173 - val_loss: 0.2713 - learning_rate: 1.0000e-04\n","Epoch 29/50\n","\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 652ms/step - accuracy: 0.9486 - loss: 0.1440\n","Epoch 29: val_loss did not improve from 0.18379\n","\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 670ms/step - accuracy: 0.9487 - loss: 0.1440 - val_accuracy: 0.9246 - val_loss: 0.2407 - learning_rate: 1.0000e-04\n","Epoch 30/50\n","\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 653ms/step - accuracy: 0.9564 - loss: 0.1420\n","Epoch 30: val_loss did not improve from 0.18379\n","\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 672ms/step - accuracy: 0.9563 - loss: 0.1420 - val_accuracy: 0.9136 - val_loss: 0.2449 - learning_rate: 1.0000e-04\n","Epoch 31/50\n","\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 673ms/step - accuracy: 0.9545 - loss: 0.1308\n","Epoch 31: val_loss improved from 0.18379 to 0.15605, saving model to ./model_checkpoints/best_model.h5\n","WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n","\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m132s\u001b[0m 709ms/step - accuracy: 0.9545 - loss: 0.1308 - val_accuracy: 0.9412 - val_loss: 0.1561 - learning_rate: 1.0000e-04\n","Epoch 32/50\n","\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 629ms/step - accuracy: 0.9587 - loss: 0.1236\n","Epoch 32: val_loss did not improve from 0.15605\n","\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 647ms/step - accuracy: 0.9587 - loss: 0.1237 - val_accuracy: 0.9449 - val_loss: 0.1797 - learning_rate: 1.0000e-04\n","Epoch 33/50\n","\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 632ms/step - accuracy: 0.9514 - loss: 0.1370\n","Epoch 33: val_loss did not improve from 0.15605\n","\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 651ms/step - accuracy: 0.9514 - loss: 0.1370 - val_accuracy: 0.9265 - val_loss: 0.2648 - learning_rate: 1.0000e-04\n","Epoch 34/50\n","\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 639ms/step - accuracy: 0.9570 - loss: 0.1287\n","Epoch 34: val_loss did not improve from 0.15605\n","\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 656ms/step - accuracy: 0.9570 - loss: 0.1288 - val_accuracy: 0.9246 - val_loss: 0.2270 - learning_rate: 1.0000e-04\n","Epoch 35/50\n","\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 643ms/step - accuracy: 0.9604 - loss: 0.1224\n","Epoch 35: val_loss did not improve from 0.15605\n","\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 662ms/step - accuracy: 0.9604 - loss: 0.1224 - val_accuracy: 0.9412 - val_loss: 0.1949 - learning_rate: 1.0000e-04\n","Epoch 36/50\n","\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 659ms/step - accuracy: 0.9564 - loss: 0.1246\n","Epoch 36: val_loss did not improve from 0.15605\n","\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 677ms/step - accuracy: 0.9564 - loss: 0.1246 - val_accuracy: 0.9412 - val_loss: 0.1654 - learning_rate: 1.0000e-04\n","Epoch 37/50\n","\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 639ms/step - accuracy: 0.9604 - loss: 0.1171\n","Epoch 37: val_loss did not improve from 0.15605\n","\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 657ms/step - accuracy: 0.9604 - loss: 0.1171 - val_accuracy: 0.9357 - val_loss: 0.1878 - learning_rate: 1.0000e-04\n","Epoch 38/50\n","\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 630ms/step - accuracy: 0.9612 - loss: 0.1195\n","Epoch 38: val_loss did not improve from 0.15605\n","\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 648ms/step - accuracy: 0.9612 - loss: 0.1195 - val_accuracy: 0.9357 - val_loss: 0.1974 - learning_rate: 1.0000e-04\n","Epoch 39/50\n","\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 596ms/step - accuracy: 0.9565 - loss: 0.1286\n","Epoch 39: val_loss did not improve from 0.15605\n","\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 613ms/step - accuracy: 0.9565 - loss: 0.1285 - val_accuracy: 0.9265 - val_loss: 0.4869 - learning_rate: 1.0000e-04\n","Epoch 40/50\n","\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 628ms/step - accuracy: 0.9621 - loss: 0.1102\n","Epoch 40: val_loss did not improve from 0.15605\n","\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 646ms/step - accuracy: 0.9620 - loss: 0.1103 - val_accuracy: 0.9210 - val_loss: 0.1864 - learning_rate: 1.0000e-04\n","Epoch 41/50\n","\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 605ms/step - accuracy: 0.9592 - loss: 0.1123\n","Epoch 41: val_loss did not improve from 0.15605\n","\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 622ms/step - accuracy: 0.9592 - loss: 0.1124 - val_accuracy: 0.9449 - val_loss: 0.2028 - learning_rate: 1.0000e-04\n","Epoch 42/50\n","\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 604ms/step - accuracy: 0.9528 - loss: 0.1331\n","Epoch 42: val_loss did not improve from 0.15605\n","\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 621ms/step - accuracy: 0.9528 - loss: 0.1330 - val_accuracy: 0.9283 - val_loss: 0.1796 - learning_rate: 1.0000e-04\n","Epoch 43/50\n","\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 625ms/step - accuracy: 0.9571 - loss: 0.1182\n","Epoch 43: val_loss did not improve from 0.15605\n","\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m120s\u001b[0m 644ms/step - accuracy: 0.9571 - loss: 0.1182 - val_accuracy: 0.9210 - val_loss: 0.2583 - learning_rate: 1.0000e-04\n","Epoch 44/50\n","\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 622ms/step - accuracy: 0.9653 - loss: 0.1001\n","Epoch 44: val_loss did not improve from 0.15605\n","\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 639ms/step - accuracy: 0.9653 - loss: 0.1002 - val_accuracy: 0.9357 - val_loss: 0.2063 - learning_rate: 1.0000e-04\n","Epoch 45/50\n","\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 635ms/step - accuracy: 0.9597 - loss: 0.1050\n","Epoch 45: val_loss did not improve from 0.15605\n","\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 653ms/step - accuracy: 0.9597 - loss: 0.1050 - val_accuracy: 0.9375 - val_loss: 0.1990 - learning_rate: 1.0000e-04\n","Epoch 46/50\n","\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 620ms/step - accuracy: 0.9623 - loss: 0.1077\n","Epoch 46: val_loss did not improve from 0.15605\n","\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 637ms/step - accuracy: 0.9623 - loss: 0.1078 - val_accuracy: 0.9430 - val_loss: 0.1664 - learning_rate: 1.0000e-04\n","Epoch 47/50\n","\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 599ms/step - accuracy: 0.9641 - loss: 0.1016\n","Epoch 47: val_loss did not improve from 0.15605\n","\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 616ms/step - accuracy: 0.9641 - loss: 0.1016 - val_accuracy: 0.9430 - val_loss: 0.1660 - learning_rate: 1.0000e-04\n","Epoch 48/50\n","\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 601ms/step - accuracy: 0.9593 - loss: 0.1074\n","Epoch 48: val_loss improved from 0.15605 to 0.13868, saving model to ./model_checkpoints/best_model.h5\n","WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n","\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m118s\u001b[0m 634ms/step - accuracy: 0.9593 - loss: 0.1074 - val_accuracy: 0.9467 - val_loss: 0.1387 - learning_rate: 1.0000e-04\n","Epoch 49/50\n","\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 599ms/step - accuracy: 0.9629 - loss: 0.1128\n","Epoch 49: val_loss did not improve from 0.13868\n","\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 616ms/step - accuracy: 0.9629 - loss: 0.1128 - val_accuracy: 0.9375 - val_loss: 0.1816 - learning_rate: 1.0000e-04\n","Epoch 50/50\n","\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 613ms/step - accuracy: 0.9509 - loss: 0.1324\n","Epoch 50: val_loss did not improve from 0.13868\n","\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m118s\u001b[0m 631ms/step - accuracy: 0.9509 - loss: 0.1324 - val_accuracy: 0.9283 - val_loss: 0.3073 - learning_rate: 1.0000e-04\n","WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n","\u001b[1m17/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 160ms/step2025-03-06 13:52:46.452466: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:557] Omitted potentially buggy algorithm eng14{k25=0} for conv (f32[30,64,224,224]{3,2,1,0}, u8[0]{0}) custom-call(f32[30,3,224,224]{3,2,1,0}, f32[64,3,3,3]{3,2,1,0}, f32[64]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"cudnn_conv_backend_config\":{\"activation_mode\":\"kRelu\",\"conv_result_scale\":1,\"leakyrelu_alpha\":0,\"side_input_scale\":0},\"force_earliest_schedule\":false,\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[]}\n","2025-03-06 13:52:46.572273: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:557] Omitted potentially buggy algorithm eng14{k25=0} for conv (f32[30,64,224,224]{3,2,1,0}, u8[0]{0}) custom-call(f32[30,64,224,224]{3,2,1,0}, f32[64,64,3,3]{3,2,1,0}, f32[64]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"cudnn_conv_backend_config\":{\"activation_mode\":\"kRelu\",\"conv_result_scale\":1,\"leakyrelu_alpha\":0,\"side_input_scale\":0},\"force_earliest_schedule\":false,\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[]}\n","2025-03-06 13:52:48.760625: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:557] Omitted potentially buggy algorithm eng14{k25=0} for conv (f32[30,128,112,112]{3,2,1,0}, u8[0]{0}) custom-call(f32[30,64,112,112]{3,2,1,0}, f32[128,64,3,3]{3,2,1,0}, f32[128]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"cudnn_conv_backend_config\":{\"activation_mode\":\"kRelu\",\"conv_result_scale\":1,\"leakyrelu_alpha\":0,\"side_input_scale\":0},\"force_earliest_schedule\":false,\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[]}\n","2025-03-06 13:52:49.711085: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:557] Omitted potentially buggy algorithm eng14{k25=0} for conv (f32[30,128,112,112]{3,2,1,0}, u8[0]{0}) custom-call(f32[30,128,112,112]{3,2,1,0}, f32[128,128,3,3]{3,2,1,0}, f32[128]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"cudnn_conv_backend_config\":{\"activation_mode\":\"kRelu\",\"conv_result_scale\":1,\"leakyrelu_alpha\":0,\"side_input_scale\":0},\"force_earliest_schedule\":false,\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[]}\n","2025-03-06 13:52:51.290542: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:557] Omitted potentially buggy algorithm eng14{k25=0} for conv (f32[30,256,56,56]{3,2,1,0}, u8[0]{0}) custom-call(f32[30,128,56,56]{3,2,1,0}, f32[256,128,3,3]{3,2,1,0}, f32[256]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"cudnn_conv_backend_config\":{\"activation_mode\":\"kRelu\",\"conv_result_scale\":1,\"leakyrelu_alpha\":0,\"side_input_scale\":0},\"force_earliest_schedule\":false,\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[]}\n","2025-03-06 13:52:52.462626: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:557] Omitted potentially buggy algorithm eng14{k25=0} for conv (f32[30,256,56,56]{3,2,1,0}, u8[0]{0}) custom-call(f32[30,256,56,56]{3,2,1,0}, f32[256,256,3,3]{3,2,1,0}, f32[256]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"cudnn_conv_backend_config\":{\"activation_mode\":\"kRelu\",\"conv_result_scale\":1,\"leakyrelu_alpha\":0,\"side_input_scale\":0},\"force_earliest_schedule\":false,\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[]}\n","2025-03-06 13:52:53.594974: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:557] Omitted potentially buggy algorithm eng14{k25=0} for conv (f32[30,512,28,28]{3,2,1,0}, u8[0]{0}) custom-call(f32[30,256,28,28]{3,2,1,0}, f32[512,256,3,3]{3,2,1,0}, f32[512]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"cudnn_conv_backend_config\":{\"activation_mode\":\"kRelu\",\"conv_result_scale\":1,\"leakyrelu_alpha\":0,\"side_input_scale\":0},\"force_earliest_schedule\":false,\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[]}\n","2025-03-06 13:52:54.298626: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:557] Omitted potentially buggy algorithm eng14{k25=0} for conv (f32[30,512,28,28]{3,2,1,0}, u8[0]{0}) custom-call(f32[30,512,28,28]{3,2,1,0}, f32[512,512,3,3]{3,2,1,0}, f32[512]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"cudnn_conv_backend_config\":{\"activation_mode\":\"kRelu\",\"conv_result_scale\":1,\"leakyrelu_alpha\":0,\"side_input_scale\":0},\"force_earliest_schedule\":false,\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[]}\n","2025-03-06 13:52:55.672033: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:557] Omitted potentially buggy algorithm eng14{k25=0} for conv (f32[30,512,14,14]{3,2,1,0}, u8[0]{0}) custom-call(f32[30,512,14,14]{3,2,1,0}, f32[512,512,3,3]{3,2,1,0}, f32[512]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"cudnn_conv_backend_config\":{\"activation_mode\":\"kRelu\",\"conv_result_scale\":1,\"leakyrelu_alpha\":0,\"side_input_scale\":0},\"force_earliest_schedule\":false,\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[]}\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 788ms/step\n","\n","0.9372822299651568\n","\n","[[ 81   0  13   0]\n"," [  1   2   7   0]\n"," [  4   0 451   0]\n"," [ 10   0   1   4]]\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.84      0.86      0.85        94\n","           1       1.00      0.20      0.33        10\n","           2       0.96      0.99      0.97       455\n","           3       1.00      0.27      0.42        15\n","\n","    accuracy                           0.94       574\n","   macro avg       0.95      0.58      0.65       574\n","weighted avg       0.94      0.94      0.93       574\n","\n"]}]},{"cell_type":"code","source":["!cp -r \"/content/gdrive/Othercomputers/My PC/Thesis/Anomaly_article_original\" \"/content/gdrive/Othercomputers/My PC/Thesis/Anomaly_article_original_after_train/\"\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xoBkfRkRwSHm","executionInfo":{"status":"ok","timestamp":1741762173624,"user_tz":-120,"elapsed":23699,"user":{"displayName":"Racheli Eliyahu","userId":"04395325802416145775"}},"outputId":"f8218cdf-4253-432c-a038-5ba8af312082"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["^C\n"]}]},{"cell_type":"code","source":["!python train_models.py  --model vgg16 --augmentation --max_epochs 50"],"metadata":{"id":"_01-UTVcbX3j","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1741762134912,"user_tz":-120,"elapsed":125,"user":{"displayName":"Racheli Eliyahu","userId":"04395325802416145775"}},"outputId":"4a021e8d-7b4d-4379-c0b9-e833082fada0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["python3: can't open file '/content/train_models.py': [Errno 2] No such file or directory\n"]}]},{"cell_type":"markdown","source":["# **Working directory - anomaly**"],"metadata":{"id":"2DX7kQ_uhIOD"}},{"cell_type":"code","source":["from google.colab import drive\n","import os\n","\n","# Mount Google Drive\n","drive.mount('/content/gdrive')\n","\n","# Define your home directory path\n","home_directory = '/content/gdrive/Othercomputers/My PC/Thesis/Anomaly_article_original'\n","\n","# Change the current working directory to your home directory\n","os.chdir(home_directory)\n","\n","# Verify the current working directory\n","print(\"Current Working Directory:\", os.getcwd())\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rIsV2D8Mh3n8","executionInfo":{"status":"ok","timestamp":1741855544786,"user_tz":-120,"elapsed":4071,"user":{"displayName":"Racheli Eliyahu","userId":"04395325802416145775"}},"outputId":"1823a49a-2e9c-48b7-e7e0-f410baf88de7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n","Current Working Directory: /content/gdrive/Othercomputers/My PC/Thesis/Anomaly_article_original\n"]}]},{"cell_type":"markdown","source":["resenet"],"metadata":{"id":"CWEa-iL8iSX5"}},{"cell_type":"code","source":["!python train_models.py  --model resnet-50 --augmentation --max_epochs 50"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HKIVEw55h9Ym","executionInfo":{"status":"ok","timestamp":1741779424527,"user_tz":-120,"elapsed":10212812,"user":{"displayName":"Racheli Eliyahu","userId":"04395325802416145775"}},"outputId":"8313230a-1a01-4055-fd2f-6efbf867d66f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["2025-03-12 08:46:52.890165: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n","E0000 00:00:1741769212.908239    5344 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","E0000 00:00:1741769212.913755    5344 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2025-03-12 08:46:52.932335: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","Found 6035 validated image filenames belonging to 4 classes.\n","Found 573 validated image filenames belonging to 4 classes.\n","Found 574 validated image filenames belonging to 4 classes.\n","2025-03-12 08:47:15.797594: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n","I0000 00:00:1741769235.799229    5344 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13942 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n","Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n","\u001b[1m94765736/94765736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 0us/step\n","Epoch 1/50\n","WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n","I0000 00:00:1741769309.683670    5488 service.cc:148] XLA service 0x7e82540022b0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n","I0000 00:00:1741769309.683792    5488 service.cc:156]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n","2025-03-12 08:48:30.514915: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n","I0000 00:00:1741769313.882939    5488 cuda_dnn.cc:529] Loaded cuDNN version 90300\n","2025-03-12 08:48:36.327598: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:557] Omitted potentially buggy algorithm eng14{k25=0} for conv (f32[32,64,56,56]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,64,56,56]{3,2,1,0}, f32[64,64,3,3]{3,2,1,0}, f32[64]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"leakyrelu_alpha\":0,\"side_input_scale\":0},\"force_earliest_schedule\":false,\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[]}\n","2025-03-12 08:48:36.748115: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:557] Omitted potentially buggy algorithm eng14{k25=0} for conv (f32[32,128,28,28]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,128,28,28]{3,2,1,0}, f32[128,128,3,3]{3,2,1,0}, f32[128]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"leakyrelu_alpha\":0,\"side_input_scale\":0},\"force_earliest_schedule\":false,\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[]}\n","2025-03-12 08:48:37.210298: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:557] Omitted potentially buggy algorithm eng14{k25=0} for conv (f32[32,256,14,14]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,256,14,14]{3,2,1,0}, f32[256,256,3,3]{3,2,1,0}, f32[256]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"leakyrelu_alpha\":0,\"side_input_scale\":0},\"force_earliest_schedule\":false,\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[]}\n","2025-03-12 08:48:37.700662: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:557] Omitted potentially buggy algorithm eng14{k25=0} for conv (f32[32,512,7,7]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,512,7,7]{3,2,1,0}, f32[512,512,3,3]{3,2,1,0}, f32[512]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"leakyrelu_alpha\":0,\"side_input_scale\":0},\"force_earliest_schedule\":false,\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[]}\n","2025-03-12 08:48:38.824032: W external/local_xla/xla/tsl/framework/bfc_allocator.cc:306] Allocator (GPU_0_bfc) ran out of memory trying to allocate 18.25GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n","I0000 00:00:1741769333.181318    5488 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20s/step - accuracy: 0.7993 - loss: 0.5769 /usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n","  self._warn_if_super_not_called()\n","\n","Epoch 1: val_loss improved from inf to 1.07816, saving model to ./model_checkpoints/best_model.h5\n","WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4053s\u001b[0m 21s/step - accuracy: 0.7998 - loss: 0.5757 - val_accuracy: 0.7831 - val_loss: 1.0782 - learning_rate: 1.0000e-04\n","Epoch 2/50\n","2025-03-12 09:55:41.836386: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:557] Omitted potentially buggy algorithm eng14{k25=0} for conv (f32[19,64,56,56]{3,2,1,0}, u8[0]{0}) custom-call(f32[19,64,56,56]{3,2,1,0}, f32[64,64,3,3]{3,2,1,0}, f32[64]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"leakyrelu_alpha\":0,\"side_input_scale\":0},\"force_earliest_schedule\":false,\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[]}\n","2025-03-12 09:55:42.116997: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:557] Omitted potentially buggy algorithm eng14{k25=0} for conv (f32[19,128,28,28]{3,2,1,0}, u8[0]{0}) custom-call(f32[19,128,28,28]{3,2,1,0}, f32[128,128,3,3]{3,2,1,0}, f32[128]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"leakyrelu_alpha\":0,\"side_input_scale\":0},\"force_earliest_schedule\":false,\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[]}\n","2025-03-12 09:55:42.394540: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:557] Omitted potentially buggy algorithm eng14{k25=0} for conv (f32[19,256,14,14]{3,2,1,0}, u8[0]{0}) custom-call(f32[19,256,14,14]{3,2,1,0}, f32[256,256,3,3]{3,2,1,0}, f32[256]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"leakyrelu_alpha\":0,\"side_input_scale\":0},\"force_earliest_schedule\":false,\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[]}\n","2025-03-12 09:55:42.658724: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:557] Omitted potentially buggy algorithm eng14{k25=0} for conv (f32[19,512,7,7]{3,2,1,0}, u8[0]{0}) custom-call(f32[19,512,7,7]{3,2,1,0}, f32[512,512,3,3]{3,2,1,0}, f32[512]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"leakyrelu_alpha\":0,\"side_input_scale\":0},\"force_earliest_schedule\":false,\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[]}\n","2025-03-12 09:55:43.288584: W external/local_xla/xla/tsl/framework/bfc_allocator.cc:306] Allocator (GPU_0_bfc) ran out of memory trying to allocate 18.18GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 600ms/step - accuracy: 0.9170 - loss: 0.2262\n","Epoch 2: val_loss did not improve from 1.07816\n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m135s\u001b[0m 615ms/step - accuracy: 0.9170 - loss: 0.2261 - val_accuracy: 0.7978 - val_loss: 1.6518 - learning_rate: 1.0000e-04\n","Epoch 3/50\n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 595ms/step - accuracy: 0.9385 - loss: 0.1785\n","Epoch 3: val_loss did not improve from 1.07816\n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 612ms/step - accuracy: 0.9385 - loss: 0.1785 - val_accuracy: 0.7978 - val_loss: 2.4322 - learning_rate: 1.0000e-04\n","Epoch 4/50\n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 594ms/step - accuracy: 0.9434 - loss: 0.1587\n","Epoch 4: val_loss improved from 1.07816 to 0.98744, saving model to ./model_checkpoints/best_model.h5\n","WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m120s\u001b[0m 638ms/step - accuracy: 0.9434 - loss: 0.1587 - val_accuracy: 0.8327 - val_loss: 0.9874 - learning_rate: 1.0000e-04\n","Epoch 5/50\n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 596ms/step - accuracy: 0.9354 - loss: 0.1831\n","Epoch 5: val_loss improved from 0.98744 to 0.52608, saving model to ./model_checkpoints/best_model.h5\n","WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 667ms/step - accuracy: 0.9354 - loss: 0.1830 - val_accuracy: 0.8529 - val_loss: 0.5261 - learning_rate: 1.0000e-04\n","Epoch 6/50\n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 592ms/step - accuracy: 0.9507 - loss: 0.1420\n","Epoch 6: val_loss improved from 0.52608 to 0.12916, saving model to ./model_checkpoints/best_model.h5\n","WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 635ms/step - accuracy: 0.9507 - loss: 0.1419 - val_accuracy: 0.9559 - val_loss: 0.1292 - learning_rate: 1.0000e-04\n","Epoch 7/50\n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 593ms/step - accuracy: 0.9585 - loss: 0.1194\n","Epoch 7: val_loss did not improve from 0.12916\n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 610ms/step - accuracy: 0.9585 - loss: 0.1195 - val_accuracy: 0.9173 - val_loss: 0.5086 - learning_rate: 1.0000e-04\n","Epoch 8/50\n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 599ms/step - accuracy: 0.9520 - loss: 0.1318\n","Epoch 8: val_loss did not improve from 0.12916\n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 614ms/step - accuracy: 0.9520 - loss: 0.1317 - val_accuracy: 0.9430 - val_loss: 0.2020 - learning_rate: 1.0000e-04\n","Epoch 9/50\n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 591ms/step - accuracy: 0.9576 - loss: 0.1159\n","Epoch 9: val_loss did not improve from 0.12916\n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 608ms/step - accuracy: 0.9576 - loss: 0.1159 - val_accuracy: 0.9357 - val_loss: 0.1858 - learning_rate: 1.0000e-04\n","Epoch 10/50\n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 594ms/step - accuracy: 0.9542 - loss: 0.1271\n","Epoch 10: val_loss did not improve from 0.12916\n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 609ms/step - accuracy: 0.9542 - loss: 0.1270 - val_accuracy: 0.9301 - val_loss: 0.2176 - learning_rate: 1.0000e-04\n","Epoch 11/50\n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 595ms/step - accuracy: 0.9599 - loss: 0.1192\n","Epoch 11: val_loss did not improve from 0.12916\n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 612ms/step - accuracy: 0.9599 - loss: 0.1192 - val_accuracy: 0.9504 - val_loss: 0.2554 - learning_rate: 1.0000e-04\n","Epoch 12/50\n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 589ms/step - accuracy: 0.9545 - loss: 0.1302\n","Epoch 12: val_loss did not improve from 0.12916\n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m113s\u001b[0m 605ms/step - accuracy: 0.9545 - loss: 0.1301 - val_accuracy: 0.9577 - val_loss: 0.1683 - learning_rate: 1.0000e-04\n","Epoch 13/50\n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 594ms/step - accuracy: 0.9664 - loss: 0.0921\n","Epoch 13: val_loss did not improve from 0.12916\n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 610ms/step - accuracy: 0.9664 - loss: 0.0922 - val_accuracy: 0.9540 - val_loss: 0.1639 - learning_rate: 1.0000e-04\n","Epoch 14/50\n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 597ms/step - accuracy: 0.9653 - loss: 0.1024\n","Epoch 14: val_loss did not improve from 0.12916\n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 612ms/step - accuracy: 0.9653 - loss: 0.1023 - val_accuracy: 0.9301 - val_loss: 0.2601 - learning_rate: 1.0000e-04\n","Epoch 15/50\n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 590ms/step - accuracy: 0.9650 - loss: 0.1030\n","Epoch 15: val_loss did not improve from 0.12916\n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 606ms/step - accuracy: 0.9650 - loss: 0.1030 - val_accuracy: 0.9430 - val_loss: 0.2073 - learning_rate: 1.0000e-04\n","Epoch 16/50\n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 595ms/step - accuracy: 0.9688 - loss: 0.0926\n","Epoch 16: val_loss did not improve from 0.12916\n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 611ms/step - accuracy: 0.9688 - loss: 0.0927 - val_accuracy: 0.9357 - val_loss: 0.2238 - learning_rate: 1.0000e-04\n","Epoch 17/50\n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 599ms/step - accuracy: 0.9729 - loss: 0.0846\n","Epoch 17: val_loss did not improve from 0.12916\n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 615ms/step - accuracy: 0.9729 - loss: 0.0846 - val_accuracy: 0.9173 - val_loss: 0.2621 - learning_rate: 1.0000e-04\n","Epoch 18/50\n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 595ms/step - accuracy: 0.9713 - loss: 0.0893\n","Epoch 18: val_loss did not improve from 0.12916\n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 611ms/step - accuracy: 0.9713 - loss: 0.0894 - val_accuracy: 0.9338 - val_loss: 0.2115 - learning_rate: 1.0000e-04\n","Epoch 19/50\n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 596ms/step - accuracy: 0.9699 - loss: 0.0870\n","Epoch 19: val_loss did not improve from 0.12916\n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 612ms/step - accuracy: 0.9699 - loss: 0.0870 - val_accuracy: 0.9375 - val_loss: 0.2127 - learning_rate: 1.0000e-04\n","Epoch 20/50\n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 595ms/step - accuracy: 0.9763 - loss: 0.0777\n","Epoch 20: val_loss did not improve from 0.12916\n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 611ms/step - accuracy: 0.9763 - loss: 0.0777 - val_accuracy: 0.9559 - val_loss: 0.1470 - learning_rate: 1.0000e-04\n","Epoch 21/50\n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 598ms/step - accuracy: 0.9700 - loss: 0.0907\n","Epoch 21: val_loss did not improve from 0.12916\n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 615ms/step - accuracy: 0.9700 - loss: 0.0907 - val_accuracy: 0.9191 - val_loss: 0.2744 - learning_rate: 1.0000e-04\n","Epoch 22/50\n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 605ms/step - accuracy: 0.9715 - loss: 0.0816\n","Epoch 22: val_loss did not improve from 0.12916\n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 621ms/step - accuracy: 0.9715 - loss: 0.0817 - val_accuracy: 0.9375 - val_loss: 0.2331 - learning_rate: 1.0000e-04\n","Epoch 23/50\n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 596ms/step - accuracy: 0.9714 - loss: 0.0882\n","Epoch 23: val_loss did not improve from 0.12916\n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 612ms/step - accuracy: 0.9714 - loss: 0.0881 - val_accuracy: 0.9412 - val_loss: 0.2209 - learning_rate: 1.0000e-04\n","Epoch 24/50\n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 598ms/step - accuracy: 0.9699 - loss: 0.0834\n","Epoch 24: val_loss did not improve from 0.12916\n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 614ms/step - accuracy: 0.9699 - loss: 0.0833 - val_accuracy: 0.9522 - val_loss: 0.1788 - learning_rate: 1.0000e-04\n","Epoch 25/50\n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 593ms/step - accuracy: 0.9749 - loss: 0.0727\n","Epoch 25: val_loss did not improve from 0.12916\n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 609ms/step - accuracy: 0.9749 - loss: 0.0728 - val_accuracy: 0.9651 - val_loss: 0.1476 - learning_rate: 1.0000e-04\n","Epoch 26/50\n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 595ms/step - accuracy: 0.9748 - loss: 0.0789\n","Epoch 26: val_loss did not improve from 0.12916\n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 611ms/step - accuracy: 0.9748 - loss: 0.0789 - val_accuracy: 0.9540 - val_loss: 0.1971 - learning_rate: 1.0000e-04\n","Epoch 27/50\n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 591ms/step - accuracy: 0.9772 - loss: 0.0736\n","Epoch 27: val_loss did not improve from 0.12916\n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 607ms/step - accuracy: 0.9772 - loss: 0.0735 - val_accuracy: 0.9669 - val_loss: 0.1447 - learning_rate: 5.0000e-05\n","Epoch 28/50\n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 595ms/step - accuracy: 0.9834 - loss: 0.0509\n","Epoch 28: val_loss did not improve from 0.12916\n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 611ms/step - accuracy: 0.9834 - loss: 0.0509 - val_accuracy: 0.9632 - val_loss: 0.1636 - learning_rate: 5.0000e-05\n","Epoch 29/50\n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 596ms/step - accuracy: 0.9801 - loss: 0.0626\n","Epoch 29: val_loss did not improve from 0.12916\n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 612ms/step - accuracy: 0.9801 - loss: 0.0625 - val_accuracy: 0.9669 - val_loss: 0.1523 - learning_rate: 5.0000e-05\n","Epoch 30/50\n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 599ms/step - accuracy: 0.9874 - loss: 0.0395\n","Epoch 30: val_loss did not improve from 0.12916\n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 615ms/step - accuracy: 0.9874 - loss: 0.0395 - val_accuracy: 0.9632 - val_loss: 0.1545 - learning_rate: 5.0000e-05\n","Epoch 31/50\n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 595ms/step - accuracy: 0.9833 - loss: 0.0499\n","Epoch 31: val_loss did not improve from 0.12916\n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 611ms/step - accuracy: 0.9833 - loss: 0.0499 - val_accuracy: 0.9393 - val_loss: 0.2540 - learning_rate: 5.0000e-05\n","Epoch 32/50\n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 589ms/step - accuracy: 0.9836 - loss: 0.0506\n","Epoch 32: val_loss did not improve from 0.12916\n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m113s\u001b[0m 605ms/step - accuracy: 0.9836 - loss: 0.0506 - val_accuracy: 0.9651 - val_loss: 0.1964 - learning_rate: 5.0000e-05\n","Epoch 33/50\n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 591ms/step - accuracy: 0.9878 - loss: 0.0413\n","Epoch 33: val_loss did not improve from 0.12916\n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 607ms/step - accuracy: 0.9878 - loss: 0.0414 - val_accuracy: 0.9596 - val_loss: 0.2118 - learning_rate: 5.0000e-05\n","Epoch 34/50\n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 601ms/step - accuracy: 0.9835 - loss: 0.0549\n","Epoch 34: val_loss did not improve from 0.12916\n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 618ms/step - accuracy: 0.9835 - loss: 0.0549 - val_accuracy: 0.9651 - val_loss: 0.1736 - learning_rate: 5.0000e-05\n","Epoch 35/50\n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 592ms/step - accuracy: 0.9842 - loss: 0.0538\n","Epoch 35: val_loss did not improve from 0.12916\n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 608ms/step - accuracy: 0.9842 - loss: 0.0537 - val_accuracy: 0.9706 - val_loss: 0.1503 - learning_rate: 5.0000e-05\n","Epoch 36/50\n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 599ms/step - accuracy: 0.9891 - loss: 0.0365\n","Epoch 36: val_loss did not improve from 0.12916\n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 616ms/step - accuracy: 0.9891 - loss: 0.0365 - val_accuracy: 0.9540 - val_loss: 0.1699 - learning_rate: 5.0000e-05\n","Epoch 37/50\n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 632ms/step - accuracy: 0.9835 - loss: 0.0497\n","Epoch 37: val_loss did not improve from 0.12916\n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 649ms/step - accuracy: 0.9835 - loss: 0.0497 - val_accuracy: 0.9632 - val_loss: 0.1550 - learning_rate: 5.0000e-05\n","Epoch 38/50\n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 630ms/step - accuracy: 0.9847 - loss: 0.0446\n","Epoch 38: val_loss did not improve from 0.12916\n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 647ms/step - accuracy: 0.9847 - loss: 0.0446 - val_accuracy: 0.9614 - val_loss: 0.2117 - learning_rate: 5.0000e-05\n","Epoch 39/50\n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 630ms/step - accuracy: 0.9897 - loss: 0.0375\n","Epoch 39: val_loss did not improve from 0.12916\n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 647ms/step - accuracy: 0.9896 - loss: 0.0376 - val_accuracy: 0.9449 - val_loss: 0.2052 - learning_rate: 5.0000e-05\n","Epoch 40/50\n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 604ms/step - accuracy: 0.9816 - loss: 0.0549\n","Epoch 40: val_loss did not improve from 0.12916\n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 621ms/step - accuracy: 0.9816 - loss: 0.0549 - val_accuracy: 0.9430 - val_loss: 0.2344 - learning_rate: 5.0000e-05\n","Epoch 41/50\n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 607ms/step - accuracy: 0.9856 - loss: 0.0435\n","Epoch 41: val_loss did not improve from 0.12916\n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 623ms/step - accuracy: 0.9856 - loss: 0.0435 - val_accuracy: 0.9596 - val_loss: 0.1997 - learning_rate: 5.0000e-05\n","Epoch 42/50\n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 609ms/step - accuracy: 0.9872 - loss: 0.0404\n","Epoch 42: val_loss did not improve from 0.12916\n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 626ms/step - accuracy: 0.9872 - loss: 0.0404 - val_accuracy: 0.9485 - val_loss: 0.3135 - learning_rate: 5.0000e-05\n","Epoch 43/50\n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 605ms/step - accuracy: 0.9820 - loss: 0.0492\n","Epoch 43: val_loss did not improve from 0.12916\n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 621ms/step - accuracy: 0.9820 - loss: 0.0491 - val_accuracy: 0.9688 - val_loss: 0.1411 - learning_rate: 5.0000e-05\n","Epoch 44/50\n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 600ms/step - accuracy: 0.9869 - loss: 0.0403\n","Epoch 44: val_loss did not improve from 0.12916\n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 616ms/step - accuracy: 0.9869 - loss: 0.0403 - val_accuracy: 0.9522 - val_loss: 0.2347 - learning_rate: 5.0000e-05\n","Epoch 45/50\n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 595ms/step - accuracy: 0.9836 - loss: 0.0439\n","Epoch 45: val_loss did not improve from 0.12916\n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 611ms/step - accuracy: 0.9836 - loss: 0.0439 - val_accuracy: 0.9596 - val_loss: 0.2451 - learning_rate: 5.0000e-05\n","Epoch 46/50\n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 592ms/step - accuracy: 0.9847 - loss: 0.0440\n","Epoch 46: val_loss did not improve from 0.12916\n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 608ms/step - accuracy: 0.9847 - loss: 0.0440 - val_accuracy: 0.9559 - val_loss: 0.2106 - learning_rate: 5.0000e-05\n","Epoch 47/50\n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 595ms/step - accuracy: 0.9845 - loss: 0.0457\n","Epoch 47: val_loss did not improve from 0.12916\n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 611ms/step - accuracy: 0.9845 - loss: 0.0456 - val_accuracy: 0.9632 - val_loss: 0.2045 - learning_rate: 2.5000e-05\n","Epoch 48/50\n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 594ms/step - accuracy: 0.9876 - loss: 0.0359\n","Epoch 48: val_loss did not improve from 0.12916\n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 610ms/step - accuracy: 0.9876 - loss: 0.0359 - val_accuracy: 0.9651 - val_loss: 0.1808 - learning_rate: 2.5000e-05\n","Epoch 49/50\n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 594ms/step - accuracy: 0.9897 - loss: 0.0300\n","Epoch 49: val_loss did not improve from 0.12916\n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 610ms/step - accuracy: 0.9897 - loss: 0.0299 - val_accuracy: 0.9743 - val_loss: 0.1792 - learning_rate: 2.5000e-05\n","Epoch 50/50\n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 617ms/step - accuracy: 0.9895 - loss: 0.0343\n","Epoch 50: val_loss did not improve from 0.12916\n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 634ms/step - accuracy: 0.9895 - loss: 0.0343 - val_accuracy: 0.9632 - val_loss: 0.1912 - learning_rate: 2.5000e-05\n","WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n","\u001b[1m17/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m17s\u001b[0m 18s/step2025-03-12 11:36:59.070540: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:557] Omitted potentially buggy algorithm eng14{k25=0} for conv (f32[30,64,56,56]{3,2,1,0}, u8[0]{0}) custom-call(f32[30,64,56,56]{3,2,1,0}, f32[64,64,3,3]{3,2,1,0}, f32[64]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"leakyrelu_alpha\":0,\"side_input_scale\":0},\"force_earliest_schedule\":false,\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[]}\n","2025-03-12 11:36:59.489302: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:557] Omitted potentially buggy algorithm eng14{k25=0} for conv (f32[30,128,28,28]{3,2,1,0}, u8[0]{0}) custom-call(f32[30,128,28,28]{3,2,1,0}, f32[128,128,3,3]{3,2,1,0}, f32[128]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"leakyrelu_alpha\":0,\"side_input_scale\":0},\"force_earliest_schedule\":false,\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[]}\n","2025-03-12 11:37:00.052894: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:557] Omitted potentially buggy algorithm eng14{k25=0} for conv (f32[30,256,14,14]{3,2,1,0}, u8[0]{0}) custom-call(f32[30,256,14,14]{3,2,1,0}, f32[256,256,3,3]{3,2,1,0}, f32[256]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"leakyrelu_alpha\":0,\"side_input_scale\":0},\"force_earliest_schedule\":false,\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[]}\n","2025-03-12 11:37:00.510706: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:557] Omitted potentially buggy algorithm eng14{k25=0} for conv (f32[30,512,7,7]{3,2,1,0}, u8[0]{0}) custom-call(f32[30,512,7,7]{3,2,1,0}, f32[512,512,3,3]{3,2,1,0}, f32[512]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"leakyrelu_alpha\":0,\"side_input_scale\":0},\"force_earliest_schedule\":false,\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[]}\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m308s\u001b[0m 18s/step\n","\n","0.9529616724738676\n","\n","[[ 81   0  13   0]\n"," [  2   3   4   1]\n"," [  5   0 450   0]\n"," [  2   0   0  13]]\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.90      0.86      0.88        94\n","           1       1.00      0.30      0.46        10\n","           2       0.96      0.99      0.98       455\n","           3       0.93      0.87      0.90        15\n","\n","    accuracy                           0.95       574\n","   macro avg       0.95      0.75      0.80       574\n","weighted avg       0.95      0.95      0.95       574\n","\n"]}]},{"cell_type":"markdown","source":["inception-v3"],"metadata":{"id":"pwgAOI8ArmjT"}},{"cell_type":"code","source":["!python train_models.py  --model inception-v3 --augmentation --max_epochs 50"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xzuYxcc6rmJO","executionInfo":{"status":"ok","timestamp":1741866234262,"user_tz":-120,"elapsed":10651631,"user":{"displayName":"Racheli Eliyahu","userId":"04395325802416145775"}},"outputId":"ce82e8c1-9f66-48ee-eae8-47f2cf44160a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["2025-03-13 08:46:24.903523: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n","E0000 00:00:1741855584.922217   20455 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","E0000 00:00:1741855584.927759   20455 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2025-03-13 08:46:24.948119: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","Found 6035 validated image filenames belonging to 4 classes.\n","Found 573 validated image filenames belonging to 4 classes.\n","Found 574 validated image filenames belonging to 4 classes.\n","2025-03-13 08:46:53.874187: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n","I0000 00:00:1741855613.876009   20455 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13942 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n","Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n","\u001b[1m87910968/87910968\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 0us/step\n","Epoch 1/50\n","WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n","I0000 00:00:1741855696.129794   20625 service.cc:148] XLA service 0x7a9470001d10 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n","I0000 00:00:1741855696.129925   20625 service.cc:156]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n","2025-03-13 08:48:17.110885: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n","I0000 00:00:1741855700.845971   20625 cuda_dnn.cc:529] Loaded cuDNN version 90300\n","I0000 00:00:1741855729.906787   20625 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22s/step - accuracy: 0.7788 - loss: 0.5759 /usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n","  self._warn_if_super_not_called()\n","\n","Epoch 1: val_loss improved from inf to 0.33081, saving model to ./model_checkpoints/best_model.h5\n","WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4505s\u001b[0m 24s/step - accuracy: 0.7792 - loss: 0.5749 - val_accuracy: 0.9007 - val_loss: 0.3308 - learning_rate: 1.0000e-04\n","Epoch 2/50\n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 609ms/step - accuracy: 0.9182 - loss: 0.2301\n","Epoch 2: val_loss improved from 0.33081 to 0.19130, saving model to ./model_checkpoints/best_model.h5\n","WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m154s\u001b[0m 645ms/step - accuracy: 0.9182 - loss: 0.2300 - val_accuracy: 0.9375 - val_loss: 0.1913 - learning_rate: 1.0000e-04\n","Epoch 3/50\n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 599ms/step - accuracy: 0.9366 - loss: 0.1839\n","Epoch 3: val_loss did not improve from 0.19130\n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 616ms/step - accuracy: 0.9366 - loss: 0.1839 - val_accuracy: 0.9283 - val_loss: 0.2210 - learning_rate: 1.0000e-04\n","Epoch 4/50\n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 592ms/step - accuracy: 0.9283 - loss: 0.1822\n","Epoch 4: val_loss improved from 0.19130 to 0.16433, saving model to ./model_checkpoints/best_model.h5\n","WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m118s\u001b[0m 631ms/step - accuracy: 0.9283 - loss: 0.1822 - val_accuracy: 0.9449 - val_loss: 0.1643 - learning_rate: 1.0000e-04\n","Epoch 5/50\n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 596ms/step - accuracy: 0.9372 - loss: 0.1733\n","Epoch 5: val_loss did not improve from 0.16433\n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 613ms/step - accuracy: 0.9372 - loss: 0.1732 - val_accuracy: 0.9357 - val_loss: 0.2234 - learning_rate: 1.0000e-04\n","Epoch 6/50\n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 598ms/step - accuracy: 0.9497 - loss: 0.1497\n","Epoch 6: val_loss did not improve from 0.16433\n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 614ms/step - accuracy: 0.9497 - loss: 0.1497 - val_accuracy: 0.9301 - val_loss: 0.2657 - learning_rate: 1.0000e-04\n","Epoch 7/50\n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 592ms/step - accuracy: 0.9578 - loss: 0.1268\n","Epoch 7: val_loss did not improve from 0.16433\n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 609ms/step - accuracy: 0.9578 - loss: 0.1269 - val_accuracy: 0.9357 - val_loss: 0.2448 - learning_rate: 1.0000e-04\n","Epoch 8/50\n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 598ms/step - accuracy: 0.9481 - loss: 0.1385\n","Epoch 8: val_loss did not improve from 0.16433\n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 614ms/step - accuracy: 0.9481 - loss: 0.1385 - val_accuracy: 0.9357 - val_loss: 0.1982 - learning_rate: 1.0000e-04\n","Epoch 9/50\n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 589ms/step - accuracy: 0.9582 - loss: 0.1267\n","Epoch 9: val_loss did not improve from 0.16433\n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 606ms/step - accuracy: 0.9582 - loss: 0.1267 - val_accuracy: 0.9449 - val_loss: 0.1836 - learning_rate: 1.0000e-04\n","Epoch 10/50\n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 595ms/step - accuracy: 0.9468 - loss: 0.1503\n","Epoch 10: val_loss did not improve from 0.16433\n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 612ms/step - accuracy: 0.9469 - loss: 0.1501 - val_accuracy: 0.9430 - val_loss: 0.2367 - learning_rate: 1.0000e-04\n","Epoch 11/50\n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 603ms/step - accuracy: 0.9596 - loss: 0.1147\n","Epoch 11: val_loss improved from 0.16433 to 0.10643, saving model to ./model_checkpoints/best_model.h5\n","WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m120s\u001b[0m 641ms/step - accuracy: 0.9596 - loss: 0.1147 - val_accuracy: 0.9688 - val_loss: 0.1064 - learning_rate: 1.0000e-04\n","Epoch 12/50\n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 586ms/step - accuracy: 0.9502 - loss: 0.1343\n","Epoch 12: val_loss did not improve from 0.10643\n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m113s\u001b[0m 602ms/step - accuracy: 0.9502 - loss: 0.1343 - val_accuracy: 0.9375 - val_loss: 0.1978 - learning_rate: 1.0000e-04\n","Epoch 13/50\n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 585ms/step - accuracy: 0.9645 - loss: 0.0961\n","Epoch 13: val_loss did not improve from 0.10643\n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m113s\u001b[0m 601ms/step - accuracy: 0.9645 - loss: 0.0962 - val_accuracy: 0.9485 - val_loss: 0.1714 - learning_rate: 1.0000e-04\n","Epoch 14/50\n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 593ms/step - accuracy: 0.9633 - loss: 0.1096\n","Epoch 14: val_loss did not improve from 0.10643\n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 609ms/step - accuracy: 0.9633 - loss: 0.1096 - val_accuracy: 0.9485 - val_loss: 0.1497 - learning_rate: 1.0000e-04\n","Epoch 15/50\n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 591ms/step - accuracy: 0.9623 - loss: 0.1050\n","Epoch 15: val_loss did not improve from 0.10643\n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 608ms/step - accuracy: 0.9623 - loss: 0.1050 - val_accuracy: 0.9301 - val_loss: 0.1968 - learning_rate: 1.0000e-04\n","Epoch 16/50\n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 599ms/step - accuracy: 0.9705 - loss: 0.0938\n","Epoch 16: val_loss did not improve from 0.10643\n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 615ms/step - accuracy: 0.9705 - loss: 0.0938 - val_accuracy: 0.9449 - val_loss: 0.2456 - learning_rate: 1.0000e-04\n","Epoch 17/50\n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 586ms/step - accuracy: 0.9616 - loss: 0.1063\n","Epoch 17: val_loss did not improve from 0.10643\n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m113s\u001b[0m 602ms/step - accuracy: 0.9616 - loss: 0.1063 - val_accuracy: 0.9301 - val_loss: 0.2604 - learning_rate: 1.0000e-04\n","Epoch 18/50\n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 586ms/step - accuracy: 0.9654 - loss: 0.0956\n","Epoch 18: val_loss did not improve from 0.10643\n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m113s\u001b[0m 602ms/step - accuracy: 0.9653 - loss: 0.0956 - val_accuracy: 0.9724 - val_loss: 0.1449 - learning_rate: 1.0000e-04\n","Epoch 19/50\n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 593ms/step - accuracy: 0.9669 - loss: 0.0968\n","Epoch 19: val_loss did not improve from 0.10643\n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 609ms/step - accuracy: 0.9669 - loss: 0.0968 - val_accuracy: 0.9504 - val_loss: 0.1522 - learning_rate: 1.0000e-04\n","Epoch 20/50\n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 596ms/step - accuracy: 0.9707 - loss: 0.0819\n","Epoch 20: val_loss did not improve from 0.10643\n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 613ms/step - accuracy: 0.9707 - loss: 0.0820 - val_accuracy: 0.9504 - val_loss: 0.1797 - learning_rate: 1.0000e-04\n","Epoch 21/50\n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 596ms/step - accuracy: 0.9652 - loss: 0.1025\n","Epoch 21: val_loss did not improve from 0.10643\n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 612ms/step - accuracy: 0.9653 - loss: 0.1024 - val_accuracy: 0.9485 - val_loss: 0.1897 - learning_rate: 1.0000e-04\n","Epoch 22/50\n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 594ms/step - accuracy: 0.9729 - loss: 0.0729\n","Epoch 22: val_loss did not improve from 0.10643\n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 610ms/step - accuracy: 0.9729 - loss: 0.0729 - val_accuracy: 0.9485 - val_loss: 0.2054 - learning_rate: 1.0000e-04\n","Epoch 23/50\n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 599ms/step - accuracy: 0.9720 - loss: 0.0835\n","Epoch 23: val_loss did not improve from 0.10643\n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 615ms/step - accuracy: 0.9719 - loss: 0.0835 - val_accuracy: 0.9467 - val_loss: 0.1662 - learning_rate: 1.0000e-04\n","Epoch 24/50\n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 598ms/step - accuracy: 0.9696 - loss: 0.0843\n","Epoch 24: val_loss did not improve from 0.10643\n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 614ms/step - accuracy: 0.9697 - loss: 0.0842 - val_accuracy: 0.9559 - val_loss: 0.1558 - learning_rate: 1.0000e-04\n","Epoch 25/50\n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 591ms/step - accuracy: 0.9734 - loss: 0.0756\n","Epoch 25: val_loss did not improve from 0.10643\n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 607ms/step - accuracy: 0.9734 - loss: 0.0757 - val_accuracy: 0.9596 - val_loss: 0.2026 - learning_rate: 1.0000e-04\n","Epoch 26/50\n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 599ms/step - accuracy: 0.9661 - loss: 0.0915\n","Epoch 26: val_loss did not improve from 0.10643\n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 615ms/step - accuracy: 0.9661 - loss: 0.0914 - val_accuracy: 0.9559 - val_loss: 0.1827 - learning_rate: 1.0000e-04\n","Epoch 27/50\n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 600ms/step - accuracy: 0.9687 - loss: 0.0830\n","Epoch 27: val_loss did not improve from 0.10643\n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 617ms/step - accuracy: 0.9688 - loss: 0.0830 - val_accuracy: 0.9338 - val_loss: 0.2288 - learning_rate: 1.0000e-04\n","Epoch 28/50\n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 600ms/step - accuracy: 0.9752 - loss: 0.0737\n","Epoch 28: val_loss did not improve from 0.10643\n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 616ms/step - accuracy: 0.9752 - loss: 0.0737 - val_accuracy: 0.9412 - val_loss: 0.1901 - learning_rate: 1.0000e-04\n","Epoch 29/50\n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 594ms/step - accuracy: 0.9735 - loss: 0.0818\n","Epoch 29: val_loss did not improve from 0.10643\n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 611ms/step - accuracy: 0.9735 - loss: 0.0818 - val_accuracy: 0.9449 - val_loss: 0.2669 - learning_rate: 1.0000e-04\n","Epoch 30/50\n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 598ms/step - accuracy: 0.9764 - loss: 0.0659\n","Epoch 30: val_loss did not improve from 0.10643\n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 614ms/step - accuracy: 0.9764 - loss: 0.0659 - val_accuracy: 0.9375 - val_loss: 0.2346 - learning_rate: 1.0000e-04\n","Epoch 31/50\n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 604ms/step - accuracy: 0.9735 - loss: 0.0752\n","Epoch 31: val_loss did not improve from 0.10643\n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 621ms/step - accuracy: 0.9735 - loss: 0.0752 - val_accuracy: 0.9265 - val_loss: 0.3280 - learning_rate: 1.0000e-04\n","Epoch 32/50\n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 595ms/step - accuracy: 0.9734 - loss: 0.0764\n","Epoch 32: val_loss did not improve from 0.10643\n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 611ms/step - accuracy: 0.9735 - loss: 0.0763 - val_accuracy: 0.9632 - val_loss: 0.1777 - learning_rate: 5.0000e-05\n","Epoch 33/50\n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 585ms/step - accuracy: 0.9854 - loss: 0.0494\n","Epoch 33: val_loss did not improve from 0.10643\n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m113s\u001b[0m 601ms/step - accuracy: 0.9854 - loss: 0.0494 - val_accuracy: 0.9706 - val_loss: 0.1722 - learning_rate: 5.0000e-05\n","Epoch 34/50\n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 588ms/step - accuracy: 0.9818 - loss: 0.0523\n","Epoch 34: val_loss did not improve from 0.10643\n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m113s\u001b[0m 604ms/step - accuracy: 0.9818 - loss: 0.0523 - val_accuracy: 0.9614 - val_loss: 0.1915 - learning_rate: 5.0000e-05\n","Epoch 35/50\n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 593ms/step - accuracy: 0.9829 - loss: 0.0591\n","Epoch 35: val_loss did not improve from 0.10643\n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 610ms/step - accuracy: 0.9829 - loss: 0.0591 - val_accuracy: 0.9632 - val_loss: 0.1880 - learning_rate: 5.0000e-05\n","Epoch 36/50\n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 597ms/step - accuracy: 0.9865 - loss: 0.0425\n","Epoch 36: val_loss did not improve from 0.10643\n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 613ms/step - accuracy: 0.9865 - loss: 0.0425 - val_accuracy: 0.9412 - val_loss: 0.2233 - learning_rate: 5.0000e-05\n","Epoch 37/50\n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 598ms/step - accuracy: 0.9791 - loss: 0.0572\n","Epoch 37: val_loss did not improve from 0.10643\n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 615ms/step - accuracy: 0.9791 - loss: 0.0571 - val_accuracy: 0.9540 - val_loss: 0.2531 - learning_rate: 5.0000e-05\n","Epoch 38/50\n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 587ms/step - accuracy: 0.9823 - loss: 0.0506\n","Epoch 38: val_loss did not improve from 0.10643\n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m113s\u001b[0m 603ms/step - accuracy: 0.9823 - loss: 0.0506 - val_accuracy: 0.9577 - val_loss: 0.2029 - learning_rate: 5.0000e-05\n","Epoch 39/50\n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 595ms/step - accuracy: 0.9877 - loss: 0.0380\n","Epoch 39: val_loss did not improve from 0.10643\n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 611ms/step - accuracy: 0.9877 - loss: 0.0381 - val_accuracy: 0.9688 - val_loss: 0.1527 - learning_rate: 5.0000e-05\n","Epoch 40/50\n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 592ms/step - accuracy: 0.9829 - loss: 0.0540\n","Epoch 40: val_loss did not improve from 0.10643\n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 608ms/step - accuracy: 0.9829 - loss: 0.0540 - val_accuracy: 0.9467 - val_loss: 0.2151 - learning_rate: 5.0000e-05\n","Epoch 41/50\n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 595ms/step - accuracy: 0.9863 - loss: 0.0450\n","Epoch 41: val_loss did not improve from 0.10643\n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 611ms/step - accuracy: 0.9863 - loss: 0.0450 - val_accuracy: 0.9577 - val_loss: 0.1725 - learning_rate: 5.0000e-05\n","Epoch 42/50\n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 587ms/step - accuracy: 0.9839 - loss: 0.0466\n","Epoch 42: val_loss did not improve from 0.10643\n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m113s\u001b[0m 603ms/step - accuracy: 0.9839 - loss: 0.0467 - val_accuracy: 0.9706 - val_loss: 0.1346 - learning_rate: 5.0000e-05\n","Epoch 43/50\n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 582ms/step - accuracy: 0.9824 - loss: 0.0497\n","Epoch 43: val_loss did not improve from 0.10643\n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m112s\u001b[0m 598ms/step - accuracy: 0.9824 - loss: 0.0497 - val_accuracy: 0.9632 - val_loss: 0.1556 - learning_rate: 5.0000e-05\n","Epoch 44/50\n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 583ms/step - accuracy: 0.9809 - loss: 0.0569\n","Epoch 44: val_loss did not improve from 0.10643\n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m112s\u001b[0m 599ms/step - accuracy: 0.9810 - loss: 0.0568 - val_accuracy: 0.9614 - val_loss: 0.1836 - learning_rate: 5.0000e-05\n","Epoch 45/50\n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 602ms/step - accuracy: 0.9815 - loss: 0.0554\n","Epoch 45: val_loss did not improve from 0.10643\n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 618ms/step - accuracy: 0.9815 - loss: 0.0553 - val_accuracy: 0.9632 - val_loss: 0.1923 - learning_rate: 5.0000e-05\n","Epoch 46/50\n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 590ms/step - accuracy: 0.9848 - loss: 0.0456\n","Epoch 46: val_loss did not improve from 0.10643\n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m113s\u001b[0m 606ms/step - accuracy: 0.9848 - loss: 0.0456 - val_accuracy: 0.9632 - val_loss: 0.1682 - learning_rate: 5.0000e-05\n","Epoch 47/50\n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 589ms/step - accuracy: 0.9842 - loss: 0.0457\n","Epoch 47: val_loss did not improve from 0.10643\n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m113s\u001b[0m 605ms/step - accuracy: 0.9842 - loss: 0.0457 - val_accuracy: 0.9669 - val_loss: 0.2020 - learning_rate: 5.0000e-05\n","Epoch 48/50\n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 595ms/step - accuracy: 0.9862 - loss: 0.0423\n","Epoch 48: val_loss did not improve from 0.10643\n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 611ms/step - accuracy: 0.9862 - loss: 0.0423 - val_accuracy: 0.9449 - val_loss: 0.2942 - learning_rate: 5.0000e-05\n","Epoch 49/50\n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 603ms/step - accuracy: 0.9833 - loss: 0.0435\n","Epoch 49: val_loss did not improve from 0.10643\n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 620ms/step - accuracy: 0.9833 - loss: 0.0435 - val_accuracy: 0.9688 - val_loss: 0.2043 - learning_rate: 5.0000e-05\n","Epoch 50/50\n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 598ms/step - accuracy: 0.9843 - loss: 0.0479\n","Epoch 50: val_loss did not improve from 0.10643\n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 615ms/step - accuracy: 0.9843 - loss: 0.0479 - val_accuracy: 0.9669 - val_loss: 0.2039 - learning_rate: 5.0000e-05\n","WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m352s\u001b[0m 20s/step\n","\n","0.9494773519163763\n","\n","[[ 83   2   8   1]\n"," [  2   7   1   0]\n"," [  7   6 442   0]\n"," [  2   0   0  13]]\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.88      0.88      0.88        94\n","           1       0.47      0.70      0.56        10\n","           2       0.98      0.97      0.98       455\n","           3       0.93      0.87      0.90        15\n","\n","    accuracy                           0.95       574\n","   macro avg       0.81      0.86      0.83       574\n","weighted avg       0.95      0.95      0.95       574\n","\n"]}]},{"cell_type":"markdown","source":["Xception"],"metadata":{"id":"LJGDmxfPhdF5"}},{"cell_type":"code","source":["!python train_models.py  --augmentation --max_epochs 50"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fo8mPv-Nhdb3","executionInfo":{"status":"ok","timestamp":1741875812124,"user_tz":-120,"elapsed":6100940,"user":{"displayName":"Racheli Eliyahu","userId":"04395325802416145775"}},"outputId":"3c46c467-c861-401d-a412-8a931c10491e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["2025-03-13 12:41:51.985690: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n","E0000 00:00:1741869712.004902   80145 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","E0000 00:00:1741869712.010810   80145 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2025-03-13 12:41:52.032016: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","Found 6035 validated image filenames belonging to 4 classes.\n","Found 573 validated image filenames belonging to 4 classes.\n","Found 574 validated image filenames belonging to 4 classes.\n","2025-03-13 12:41:56.820008: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n","I0000 00:00:1741869716.820196   80145 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13942 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n","Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/xception/xception_weights_tf_dim_ordering_tf_kernels_notop.h5\n","\u001b[1m83683744/83683744\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 0us/step\n","Epoch 1/50\n","WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n","I0000 00:00:1741869744.899964   80212 service.cc:148] XLA service 0x7be6d4001ce0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n","I0000 00:00:1741869744.900003   80212 service.cc:156]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n","2025-03-13 12:42:25.383217: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n","I0000 00:00:1741869747.592394   80212 cuda_dnn.cc:529] Loaded cuDNN version 90300\n","2025-03-13 12:42:32.803334: W external/local_xla/xla/tsl/framework/bfc_allocator.cc:378] Garbage collection: deallocate free memory regions (i.e., allocations) so that we can re-allocate a larger region to avoid OOM due to memory fragmentation. If you see this message frequently, you are running near the threshold of the available device memory and re-allocation may incur great performance overhead. You may try smaller batch sizes to observe the performance impact. Set TF_ENABLE_GPU_GARBAGE_COLLECTION=false if you'd like to disable this feature.\n","E0000 00:00:1741869760.374427   80212 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n","E0000 00:00:1741869760.556153   80212 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n","E0000 00:00:1741869761.624519   80212 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n","E0000 00:00:1741869761.764672   80212 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n","I0000 00:00:1741869769.860277   80212 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 651ms/step - accuracy: 0.7892 - loss: 0.6187/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n","  self._warn_if_super_not_called()\n","\n","Epoch 1: val_loss improved from inf to 0.21479, saving model to ./model_checkpoints/best_model.h5\n","WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m173s\u001b[0m 688ms/step - accuracy: 0.7897 - loss: 0.6174 - val_accuracy: 0.9338 - val_loss: 0.2148 - learning_rate: 1.0000e-04\n","Epoch 2/50\n","E0000 00:00:1741869910.460471   80212 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n","E0000 00:00:1741869910.620661   80212 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n","E0000 00:00:1741869911.554083   80212 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n","E0000 00:00:1741869911.690029   80212 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 632ms/step - accuracy: 0.9279 - loss: 0.2076\n","Epoch 2: val_loss improved from 0.21479 to 0.18442, saving model to ./model_checkpoints/best_model.h5\n","WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m146s\u001b[0m 666ms/step - accuracy: 0.9279 - loss: 0.2076 - val_accuracy: 0.9357 - val_loss: 0.1844 - learning_rate: 1.0000e-04\n","Epoch 3/50\n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 631ms/step - accuracy: 0.9441 - loss: 0.1563\n","Epoch 3: val_loss improved from 0.18442 to 0.16189, saving model to ./model_checkpoints/best_model.h5\n","WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 667ms/step - accuracy: 0.9441 - loss: 0.1563 - val_accuracy: 0.9338 - val_loss: 0.1619 - learning_rate: 1.0000e-04\n","Epoch 4/50\n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 624ms/step - accuracy: 0.9493 - loss: 0.1482\n","Epoch 4: val_loss did not improve from 0.16189\n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m120s\u001b[0m 641ms/step - accuracy: 0.9493 - loss: 0.1481 - val_accuracy: 0.9449 - val_loss: 0.1676 - learning_rate: 1.0000e-04\n","Epoch 5/50\n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 629ms/step - accuracy: 0.9529 - loss: 0.1383\n","Epoch 5: val_loss improved from 0.16189 to 0.15253, saving model to ./model_checkpoints/best_model.h5\n","WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 665ms/step - accuracy: 0.9529 - loss: 0.1383 - val_accuracy: 0.9467 - val_loss: 0.1525 - learning_rate: 1.0000e-04\n","Epoch 6/50\n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 621ms/step - accuracy: 0.9593 - loss: 0.1217\n","Epoch 6: val_loss did not improve from 0.15253\n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m120s\u001b[0m 638ms/step - accuracy: 0.9593 - loss: 0.1217 - val_accuracy: 0.9449 - val_loss: 0.1598 - learning_rate: 1.0000e-04\n","Epoch 7/50\n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 634ms/step - accuracy: 0.9678 - loss: 0.0977\n","Epoch 7: val_loss improved from 0.15253 to 0.14162, saving model to ./model_checkpoints/best_model.h5\n","WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 672ms/step - accuracy: 0.9678 - loss: 0.0977 - val_accuracy: 0.9467 - val_loss: 0.1416 - learning_rate: 1.0000e-04\n","Epoch 8/50\n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 618ms/step - accuracy: 0.9654 - loss: 0.0909\n","Epoch 8: val_loss did not improve from 0.14162\n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 635ms/step - accuracy: 0.9654 - loss: 0.0909 - val_accuracy: 0.9393 - val_loss: 0.1946 - learning_rate: 1.0000e-04\n","Epoch 9/50\n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 626ms/step - accuracy: 0.9640 - loss: 0.0968\n","Epoch 9: val_loss did not improve from 0.14162\n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 643ms/step - accuracy: 0.9640 - loss: 0.0968 - val_accuracy: 0.9301 - val_loss: 0.2029 - learning_rate: 1.0000e-04\n","Epoch 10/50\n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 626ms/step - accuracy: 0.9631 - loss: 0.1090\n","Epoch 10: val_loss did not improve from 0.14162\n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 643ms/step - accuracy: 0.9631 - loss: 0.1089 - val_accuracy: 0.9338 - val_loss: 0.1809 - learning_rate: 1.0000e-04\n","Epoch 11/50\n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 623ms/step - accuracy: 0.9697 - loss: 0.0916\n","Epoch 11: val_loss improved from 0.14162 to 0.13613, saving model to ./model_checkpoints/best_model.h5\n","WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 658ms/step - accuracy: 0.9697 - loss: 0.0915 - val_accuracy: 0.9485 - val_loss: 0.1361 - learning_rate: 1.0000e-04\n","Epoch 12/50\n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 630ms/step - accuracy: 0.9673 - loss: 0.0844\n","Epoch 12: val_loss did not improve from 0.13613\n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 647ms/step - accuracy: 0.9673 - loss: 0.0844 - val_accuracy: 0.9375 - val_loss: 0.2027 - learning_rate: 1.0000e-04\n","Epoch 13/50\n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 639ms/step - accuracy: 0.9797 - loss: 0.0594\n","Epoch 13: val_loss did not improve from 0.13613\n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 655ms/step - accuracy: 0.9796 - loss: 0.0594 - val_accuracy: 0.9412 - val_loss: 0.2023 - learning_rate: 1.0000e-04\n","Epoch 14/50\n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 641ms/step - accuracy: 0.9712 - loss: 0.0799\n","Epoch 14: val_loss did not improve from 0.13613\n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 657ms/step - accuracy: 0.9712 - loss: 0.0799 - val_accuracy: 0.9540 - val_loss: 0.1479 - learning_rate: 1.0000e-04\n","Epoch 15/50\n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 630ms/step - accuracy: 0.9773 - loss: 0.0735\n","Epoch 15: val_loss improved from 0.13613 to 0.13584, saving model to ./model_checkpoints/best_model.h5\n","WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 673ms/step - accuracy: 0.9773 - loss: 0.0735 - val_accuracy: 0.9577 - val_loss: 0.1358 - learning_rate: 1.0000e-04\n","Epoch 16/50\n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 619ms/step - accuracy: 0.9783 - loss: 0.0648\n","Epoch 16: val_loss did not improve from 0.13584\n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 637ms/step - accuracy: 0.9783 - loss: 0.0649 - val_accuracy: 0.9467 - val_loss: 0.1545 - learning_rate: 1.0000e-04\n","Epoch 17/50\n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 624ms/step - accuracy: 0.9763 - loss: 0.0664\n","Epoch 17: val_loss did not improve from 0.13584\n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m120s\u001b[0m 641ms/step - accuracy: 0.9763 - loss: 0.0664 - val_accuracy: 0.9559 - val_loss: 0.1625 - learning_rate: 1.0000e-04\n","Epoch 18/50\n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 618ms/step - accuracy: 0.9823 - loss: 0.0547\n","Epoch 18: val_loss did not improve from 0.13584\n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 635ms/step - accuracy: 0.9823 - loss: 0.0548 - val_accuracy: 0.9412 - val_loss: 0.2534 - learning_rate: 1.0000e-04\n","Epoch 19/50\n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 617ms/step - accuracy: 0.9748 - loss: 0.0767\n","Epoch 19: val_loss did not improve from 0.13584\n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 633ms/step - accuracy: 0.9748 - loss: 0.0766 - val_accuracy: 0.9467 - val_loss: 0.1665 - learning_rate: 1.0000e-04\n","Epoch 20/50\n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 622ms/step - accuracy: 0.9820 - loss: 0.0580\n","Epoch 20: val_loss did not improve from 0.13584\n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m120s\u001b[0m 640ms/step - accuracy: 0.9820 - loss: 0.0580 - val_accuracy: 0.9632 - val_loss: 0.1396 - learning_rate: 1.0000e-04\n","Epoch 21/50\n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 608ms/step - accuracy: 0.9795 - loss: 0.0696\n","Epoch 21: val_loss improved from 0.13584 to 0.13544, saving model to ./model_checkpoints/best_model.h5\n","WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 644ms/step - accuracy: 0.9795 - loss: 0.0695 - val_accuracy: 0.9559 - val_loss: 0.1354 - learning_rate: 1.0000e-04\n","Epoch 22/50\n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 613ms/step - accuracy: 0.9858 - loss: 0.0446\n","Epoch 22: val_loss improved from 0.13544 to 0.13100, saving model to ./model_checkpoints/best_model.h5\n","WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 654ms/step - accuracy: 0.9858 - loss: 0.0447 - val_accuracy: 0.9688 - val_loss: 0.1310 - learning_rate: 1.0000e-04\n","Epoch 23/50\n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 606ms/step - accuracy: 0.9824 - loss: 0.0513\n","Epoch 23: val_loss did not improve from 0.13100\n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 622ms/step - accuracy: 0.9824 - loss: 0.0513 - val_accuracy: 0.9522 - val_loss: 0.1553 - learning_rate: 1.0000e-04\n","Epoch 24/50\n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 619ms/step - accuracy: 0.9847 - loss: 0.0464\n","Epoch 24: val_loss did not improve from 0.13100\n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 635ms/step - accuracy: 0.9847 - loss: 0.0464 - val_accuracy: 0.9651 - val_loss: 0.1488 - learning_rate: 1.0000e-04\n","Epoch 25/50\n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 613ms/step - accuracy: 0.9829 - loss: 0.0535\n","Epoch 25: val_loss did not improve from 0.13100\n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m118s\u001b[0m 630ms/step - accuracy: 0.9829 - loss: 0.0535 - val_accuracy: 0.9577 - val_loss: 0.1883 - learning_rate: 1.0000e-04\n","Epoch 26/50\n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 608ms/step - accuracy: 0.9786 - loss: 0.0600\n","Epoch 26: val_loss did not improve from 0.13100\n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 624ms/step - accuracy: 0.9786 - loss: 0.0600 - val_accuracy: 0.9540 - val_loss: 0.1853 - learning_rate: 1.0000e-04\n","Epoch 27/50\n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 605ms/step - accuracy: 0.9817 - loss: 0.0517\n","Epoch 27: val_loss did not improve from 0.13100\n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 622ms/step - accuracy: 0.9817 - loss: 0.0517 - val_accuracy: 0.9632 - val_loss: 0.1654 - learning_rate: 1.0000e-04\n","Epoch 28/50\n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 609ms/step - accuracy: 0.9834 - loss: 0.0497\n","Epoch 28: val_loss did not improve from 0.13100\n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 626ms/step - accuracy: 0.9834 - loss: 0.0498 - val_accuracy: 0.9485 - val_loss: 0.1859 - learning_rate: 1.0000e-04\n","Epoch 29/50\n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 612ms/step - accuracy: 0.9824 - loss: 0.0534\n","Epoch 29: val_loss did not improve from 0.13100\n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m118s\u001b[0m 629ms/step - accuracy: 0.9824 - loss: 0.0534 - val_accuracy: 0.9651 - val_loss: 0.1548 - learning_rate: 1.0000e-04\n","Epoch 30/50\n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 607ms/step - accuracy: 0.9904 - loss: 0.0362\n","Epoch 30: val_loss did not improve from 0.13100\n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 623ms/step - accuracy: 0.9904 - loss: 0.0362 - val_accuracy: 0.9320 - val_loss: 0.2721 - learning_rate: 1.0000e-04\n","Epoch 31/50\n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 608ms/step - accuracy: 0.9852 - loss: 0.0506\n","Epoch 31: val_loss did not improve from 0.13100\n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 625ms/step - accuracy: 0.9852 - loss: 0.0507 - val_accuracy: 0.9559 - val_loss: 0.1676 - learning_rate: 1.0000e-04\n","Epoch 32/50\n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 605ms/step - accuracy: 0.9808 - loss: 0.0544\n","Epoch 32: val_loss did not improve from 0.13100\n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 621ms/step - accuracy: 0.9808 - loss: 0.0544 - val_accuracy: 0.9743 - val_loss: 0.1321 - learning_rate: 1.0000e-04\n","Epoch 33/50\n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 606ms/step - accuracy: 0.9868 - loss: 0.0472\n","Epoch 33: val_loss did not improve from 0.13100\n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 623ms/step - accuracy: 0.9867 - loss: 0.0472 - val_accuracy: 0.9596 - val_loss: 0.1613 - learning_rate: 1.0000e-04\n","Epoch 34/50\n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 604ms/step - accuracy: 0.9853 - loss: 0.0490\n","Epoch 34: val_loss did not improve from 0.13100\n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 621ms/step - accuracy: 0.9853 - loss: 0.0490 - val_accuracy: 0.9632 - val_loss: 0.1899 - learning_rate: 1.0000e-04\n","Epoch 35/50\n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 611ms/step - accuracy: 0.9820 - loss: 0.0510\n","Epoch 35: val_loss did not improve from 0.13100\n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m118s\u001b[0m 628ms/step - accuracy: 0.9820 - loss: 0.0510 - val_accuracy: 0.9577 - val_loss: 0.2051 - learning_rate: 1.0000e-04\n","Epoch 36/50\n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 609ms/step - accuracy: 0.9857 - loss: 0.0412\n","Epoch 36: val_loss did not improve from 0.13100\n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 625ms/step - accuracy: 0.9857 - loss: 0.0412 - val_accuracy: 0.9614 - val_loss: 0.1532 - learning_rate: 1.0000e-04\n","Epoch 37/50\n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 613ms/step - accuracy: 0.9832 - loss: 0.0478\n","Epoch 37: val_loss did not improve from 0.13100\n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m118s\u001b[0m 630ms/step - accuracy: 0.9832 - loss: 0.0478 - val_accuracy: 0.9632 - val_loss: 0.1531 - learning_rate: 1.0000e-04\n","Epoch 38/50\n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 605ms/step - accuracy: 0.9837 - loss: 0.0485\n","Epoch 38: val_loss did not improve from 0.13100\n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 621ms/step - accuracy: 0.9837 - loss: 0.0485 - val_accuracy: 0.9724 - val_loss: 0.1792 - learning_rate: 1.0000e-04\n","Epoch 39/50\n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 610ms/step - accuracy: 0.9903 - loss: 0.0330\n","Epoch 39: val_loss did not improve from 0.13100\n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m118s\u001b[0m 627ms/step - accuracy: 0.9903 - loss: 0.0330 - val_accuracy: 0.9724 - val_loss: 0.1361 - learning_rate: 1.0000e-04\n","Epoch 40/50\n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 609ms/step - accuracy: 0.9885 - loss: 0.0375\n","Epoch 40: val_loss did not improve from 0.13100\n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 626ms/step - accuracy: 0.9885 - loss: 0.0375 - val_accuracy: 0.9540 - val_loss: 0.1949 - learning_rate: 1.0000e-04\n","Epoch 41/50\n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 612ms/step - accuracy: 0.9854 - loss: 0.0526\n","Epoch 41: val_loss did not improve from 0.13100\n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m118s\u001b[0m 628ms/step - accuracy: 0.9854 - loss: 0.0526 - val_accuracy: 0.9596 - val_loss: 0.2160 - learning_rate: 1.0000e-04\n","Epoch 42/50\n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 613ms/step - accuracy: 0.9859 - loss: 0.0398\n","Epoch 42: val_loss did not improve from 0.13100\n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m118s\u001b[0m 629ms/step - accuracy: 0.9859 - loss: 0.0398 - val_accuracy: 0.9596 - val_loss: 0.1688 - learning_rate: 1.0000e-04\n","Epoch 43/50\n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 608ms/step - accuracy: 0.9912 - loss: 0.0429\n","Epoch 43: val_loss did not improve from 0.13100\n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 624ms/step - accuracy: 0.9911 - loss: 0.0429 - val_accuracy: 0.9596 - val_loss: 0.1621 - learning_rate: 5.0000e-05\n","Epoch 44/50\n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 600ms/step - accuracy: 0.9884 - loss: 0.0369\n","Epoch 44: val_loss did not improve from 0.13100\n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 618ms/step - accuracy: 0.9884 - loss: 0.0369 - val_accuracy: 0.9669 - val_loss: 0.1346 - learning_rate: 5.0000e-05\n","Epoch 45/50\n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 615ms/step - accuracy: 0.9876 - loss: 0.0389\n","Epoch 45: val_loss did not improve from 0.13100\n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 632ms/step - accuracy: 0.9876 - loss: 0.0389 - val_accuracy: 0.9669 - val_loss: 0.1713 - learning_rate: 5.0000e-05\n","Epoch 46/50\n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 601ms/step - accuracy: 0.9910 - loss: 0.0331\n","Epoch 46: val_loss did not improve from 0.13100\n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 617ms/step - accuracy: 0.9910 - loss: 0.0331 - val_accuracy: 0.9724 - val_loss: 0.1357 - learning_rate: 5.0000e-05\n","Epoch 47/50\n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 610ms/step - accuracy: 0.9887 - loss: 0.0313\n","Epoch 47: val_loss did not improve from 0.13100\n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m118s\u001b[0m 627ms/step - accuracy: 0.9887 - loss: 0.0313 - val_accuracy: 0.9614 - val_loss: 0.1617 - learning_rate: 5.0000e-05\n","Epoch 48/50\n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 612ms/step - accuracy: 0.9914 - loss: 0.0295\n","Epoch 48: val_loss did not improve from 0.13100\n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m118s\u001b[0m 629ms/step - accuracy: 0.9914 - loss: 0.0295 - val_accuracy: 0.9651 - val_loss: 0.1548 - learning_rate: 5.0000e-05\n","Epoch 49/50\n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 609ms/step - accuracy: 0.9914 - loss: 0.0284\n","Epoch 49: val_loss did not improve from 0.13100\n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 626ms/step - accuracy: 0.9914 - loss: 0.0284 - val_accuracy: 0.9706 - val_loss: 0.1678 - learning_rate: 5.0000e-05\n","Epoch 50/50\n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 593ms/step - accuracy: 0.9891 - loss: 0.0314\n","Epoch 50: val_loss did not improve from 0.13100\n","\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 610ms/step - accuracy: 0.9891 - loss: 0.0314 - val_accuracy: 0.9669 - val_loss: 0.1738 - learning_rate: 5.0000e-05\n","WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 526ms/step\n","\n","0.9564459930313589\n","\n","[[ 81   1  12   0]\n"," [  1   5   4   0]\n"," [  3   0 452   0]\n"," [  1   0   3  11]]\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.94      0.86      0.90        94\n","           1       0.83      0.50      0.62        10\n","           2       0.96      0.99      0.98       455\n","           3       1.00      0.73      0.85        15\n","\n","    accuracy                           0.96       574\n","   macro avg       0.93      0.77      0.84       574\n","weighted avg       0.96      0.96      0.95       574\n","\n"]}]}]}